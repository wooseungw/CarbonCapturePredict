{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ViT(Vision Transformer)**"
      ],
      "metadata": {
        "id": "X8DX_Kg7XPtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2020년 구글의 「An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale」 논문에서 소개된 이미지 인식을 위한 딥러닝 모델\n",
        "*   이미지를 자연어 처리 방식처럼 분류해 보려는 시도에 의해 탄생\n",
        "*   이미지 분류 모델에서 사용되는 CNN 모델의 합성곱 계층 방법을 사용하지 않고 트렌스포머 모델에서 사용되는 셀프 어텐션 적용\n",
        "*   셀프 어텐션을 사용해 이미지를 한 번에 처리하는 방식\n",
        "*   이미지 패치가 왼쪽에서 오른쪽, 위에서 아래의 방향으로 순차적으로 입력되어 2차원 구조의 이미지 특성을 온전히 반영한다고 할 수 없음\n",
        "*   이를 해결하기 위해 물체의 크기나 해상도를 계층적으로 학습하는 스윈 트랜스포머(Swin Transformer)와 CvT(Convolutional Vision Transformer) 모델이 제안됨\n",
        "*   스윈 트랜스포머: 로컬 윈도를 사용해 각 계층의 어텐션이 되는 패치의 크기와 개수를 다양하게 구성\n",
        "*   CvT: 기존 합성곱 연산 과정을 ViT에 적용한 모델, 저수준 특징과 고수준 특징을 계층적으로 반영\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M5XWeUeaXaH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**BERT 모델과 ViT 모델 구조의 차이**\n",
        "*   BERT와 ViT 모델 모두 트랜스포머 모델의 구조를 그대로 사용하지만, 입력 데이터를 만드는 과정이 서로 다름\n",
        "*   BERT: 문장보다 작은 단위의 토큰들이 순차적으로 입력, ViT: 이미지가 격자로 작은 단위의 이미지 패치로 나뉘어 순차적으로 입력\n",
        "*   ViT에서 사용되는 입력 이미지 패치는 왼쪽에서 오른쪽, 위에서 아래로 표현된 시퀀셜 배열을 가정함\n"
      ],
      "metadata": {
        "id": "sIhQsOk3aqGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**합성곱 신경망과 ViT 계층의 차이**\n",
        "*   합성곱 신경망과 트랜스포머는 이미지 특징을 잘 표현하는 임베딩을 만들고자 하는 목적은 같지만, 과정에는 큰 차이가 있음\n",
        "*   합성곱 신경망의 임베딩은 이미지 패치 중 일부만 선택해 학습하며, 이를 통해 이미지 전체의 특징 추출\n",
        "*   ex) 고양이의 이미지에서 왼쪽 눈의 특징을 추출하고자 한다면 합성곱 신경망은 이미지에서 해당 부분만 선택해 학습\n",
        "*   ViT 임베딩은 이미지를 작은 패치들로 나누어 각 패치 간의 상관관계 학습\n",
        "*   이를 위해 셀프 어텐션 방법을 사용해 모든 이미지 패치가 서로에게 주는 영향을 고려해 이미지의 전체 특징 추출 → 모든 이미지 패치가 학습에 관여하며 높은 수준의 이미지 표현 제공\n",
        "*   좁은 수용 영역(Receptive Field, RF)을 가진 합성곱 신경망은 전체 이미지 정보를 표현하는 데 수많은 계층이 필요\n",
        "*   트랜스포머 모델은 어텐션 거리를 계산해 오직 한 개의 ViT 레이어로 전체 이미지 정보를 쉽게 표현\n",
        "*   또한, 픽셀 단위로 처리하는 합성곱 모델과 달리 패치 단위로 이미지를 처리하므로 더 작은 모델로도 높은 성능을 얻을 수 있음\n",
        "*   ViT 모델은 입력 이미지의 크기가 고정되어 있어 크기가 다른 이미지를 처리하려면 이미지 크기를 맞추는 전처리가 필요하며, 합성곱 신경망이 이미지의 공간적인 위치 정보를 고려하는 데 비해 ViT는 패치 간의 상대적인 위치만 고려하기 때문에 이미지 변환에 취약함\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JAlo9-Sxbk6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ViT의 귀납적 편향**\n",
        "*   딥러닝 모델의 귀납적 편향(Inductive Bias)은 일반화 성능 향상을 위한 모델 가정을 의미\n",
        "*   이미지 데이터는 공간적 관계를 잘 표현하므로 지역적(Local) 편향을 가진 합성곱 신경망 모델이 많이 사용\n",
        "*   합성곱 신경망은 이미지를 작은 조각으로 나누어 각 조각의 특징을 추출한 후, 이들을 조합해 전체 이미지의 특징 추론 → 지역적인 특징을 강조하는 특성을 가지고 있어 이미지 데이터에서 좋은 성능 발휘\n",
        "*   ViT 모델은 입력 데이터의 다양한 쿼리, 키, 값의 임베딩 형태로 일반화된 관계를 학습하기 때문에 귀납적 편향이 거의 없고, 대용량 데이터에 대해 이미지 특징들의 관계를 잘 학습하는 모델로 알려져 있음\n",
        "*   귀납적 편향: 해당 모델이 가지는 구조와 매개변수들이 데이터에 적합한 가정을 하고 있음을 나타냄 → 가정이 올바르면 모델은 더 적은 데이터로 높은 일반화 성능을 보임, 너무 강한 귀납적 편향은 다른 유형의 데이터나 관계를 표현하는 데 어려움 초래\n",
        "\n"
      ],
      "metadata": {
        "id": "_XL9JBfSc1St"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ViT 모델**\n",
        "*   입력 이미지를 트랜스포머 구조에 맞게 일정한 크기의 패치로 나눈 다음 각 패치를 벡터 형태로 변환하는 패치 임베딩(Patch Embedding)과 각 패치와의 관계를 학습하는 인코더 계층으로 구성\n",
        "*   패치 임베딩과 인코더 계층을 사용해 이미지의 특징을 추출하고 분류나 회귀와 같은 작업에 맞는 출력값으로 변환해 사용\n",
        "*   ViT 모델 구조\n",
        " <img src = \"https://drive.google.com/uc?export=view&id=1HhpahSWw9vMH7mARP8vZfMJNZ1LdPIfC\" height = 200 width = 400>"
      ],
      "metadata": {
        "id": "g--4p7j_dnf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**패치 임베딩**\n",
        "*   입력 이미지를 작은 패치로 분할하는 과정\n",
        "*   작은 패치로 분할하기 위해서는 이미지 크기를 맞추는 전처리 수행\n",
        "*   이미지 크기를 일정한 크기로 변경했다면 전체 이미지를 패치 크기로 분할해 시퀀셜 배열을 만듦(이때 합성곱 신경망의 계층 활용)\n",
        "*   이미지 패치 생성 과정 사진\n",
        "*   패치 임베딩을 위해서는 커널 크기와 간격 설정(하이퍼파라미터로 정의, 커널: 패치의 크기, 간격: 패치가 이동하는 폭)\n",
        "*   이미지 크기가 9x9, 커널 크기가 3x3, 간격이 3이라면 총 9(3x3)개의 이미지 패치 생성\n",
        "*   가로 또는 새로 패치의 개수를 계산하는 과정   \n",
        " <img src = \"https://drive.google.com/uc?export=view&id=1zT_gNkpKDeSIX1VR4GKMwMVw978CAEF0\" height = 50 width = 300>\n",
        "*   위 수식과 같이 가로 패치는 3개, 세로 패치도 3개가 생성되어 총 9개의 패치 생성\n",
        "*   커널 크기가 3x3, 간격이 1이라면 (9-3+1)x(9-3+1)=49개의 패치 생성\n",
        "*   일반적으로 분할된 이미지 패치들을 배열 형태로 나열할 때 왼쪽에서 오른쪽, 위에서 아래의 순서로 배열\n",
        "*   이 배열 가장 왼쪽에 분류 토큰(Special Classfication Token, [CLS])을 추가\n",
        "*   분류 토큰은 전체 이미지를 대표하는 벡터로 특정 문제를 예측하는 데 사용\n",
        "*   또한, 위치 임베딩(Position Embedding)을 사용해 인접한 패치 간의 관계 학습, 패치의 위치 정보를 임베딩 벡터로 변환하고 기존 이미지 패치 벡터들과 더함\n",
        "*   마지막에 계층 정규화를 적용하면 패치 임베딩이 만들어짐\n",
        "*   이렇게 입력 이미지를 작은 패치로 나눠 처리하면 GPU 메모리의 한계를 극복하고 더 큰 이미지 처리 가능\n",
        "\n"
      ],
      "metadata": {
        "id": "L54woujJeWSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**인코더 계층**\n",
        "*   ViT 모델은 이미지를 일정한 크기의 패치로 나누어 각 패치를 벡터로 변환한 후 인코더 계층에 입력으로 전달해 다양한 쿼리, 키, 값 임베딩 관계를 학습\n",
        "*   N개의 인코더 레이어를 반복적으로 적용한 후, 마지막 레이어에서는 분류 토큰이라고 불리는 특별한 패치의 특징 벡터 추출\n",
        "*   이 분류 토큰 벡터는 이미지 데이터를 잘 표현하는 특징 벡터로 간주됨 → 특징 벡터는 이후 다양한 이미지 분류 및 검색 문제를 해결하는 데 사용\n",
        "*   ex) 고양이인지 아닌지 구분하는 모델을 학습한다면 ViT 모델은 시퀀셜 산출물(Sequential Output)을 모두 사용하는 것이 아니라 전체 이미지의 특징을 잘 표현하는 분류 토큰 벡터만 사용해 분류 문제를 풀어냄 → 분류 토큰 벡터를 순방향 신경망(또는 완전 연결 계층)에 연결하고 고양이인지 아닌지를 분류하는 방법으로 모델 학습\n",
        "\n"
      ],
      "metadata": {
        "id": "gBar9z3-gAui"
      }
    }
  ]
}