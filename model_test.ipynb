{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                                           Input Shape               Output Shape              Param #\n",
       "======================================================================================================================================================\n",
       "Segformerwithcarbon (Segformerwithcarbon)                                   [2, 4, 256, 256]          [2, 7, 64, 64]            --\n",
       "├─MiT (mit): 1-1                                                            [2, 4, 256, 256]          [2, 64, 64, 64]           --\n",
       "│    └─ModuleList (stages): 2-1                                             --                        --                        --\n",
       "│    │    └─ModuleList (0): 3-1                                             --                        --                        --\n",
       "│    │    │    └─Unfold (0): 4-1                                            [2, 4, 256, 256]          [2, 196, 4096]            --\n",
       "│    │    │    └─Conv2d (1): 4-2                                            [2, 196, 64, 64]          [2, 64, 64, 64]           12,608\n",
       "│    │    │    └─ModuleList (2): 4-3                                        --                        --                        --\n",
       "│    │    │    │    └─ModuleList (0): 5-1                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-1                                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-1                       [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-2            [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-1                     [2, 64, 64, 64]           [2, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-2                    [2, 64, 64, 64]           [2, 128, 8, 8]            524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-3                   [2, 64, 64, 64]           [2, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    └─PreNorm (1): 6-2                                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-3                       [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-4                    [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-4                  [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-1                   [2, 64, 64, 64]           [2, 512, 64, 64]          33,280\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-2                 [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-1       [2, 512, 64, 64]          [2, 512, 64, 64]          267,776\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-3                     [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-4                   [2, 512, 64, 64]          [2, 64, 64, 64]           32,832\n",
       "│    │    │    │    └─ModuleList (1): 5-2                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-3                                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-5                       [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-6            [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-5                     [2, 64, 64, 64]           [2, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-6                    [2, 64, 64, 64]           [2, 128, 8, 8]            524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-7                   [2, 64, 64, 64]           [2, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    └─PreNorm (1): 6-4                                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-7                       [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-8                    [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-8                  [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-5                   [2, 64, 64, 64]           [2, 512, 64, 64]          33,280\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-6                 [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-2       [2, 512, 64, 64]          [2, 512, 64, 64]          267,776\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-7                     [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-8                   [2, 512, 64, 64]          [2, 64, 64, 64]           32,832\n",
       "│    │    └─ModuleList (1): 3-2                                             --                        --                        --\n",
       "│    │    │    └─Unfold (0): 4-4                                            [2, 64, 64, 64]           [2, 576, 1024]            --\n",
       "│    │    │    └─Conv2d (1): 4-5                                            [2, 576, 32, 32]          [2, 128, 32, 32]          73,856\n",
       "│    │    │    └─ModuleList (2): 4-6                                        --                        --                        --\n",
       "│    │    │    │    └─ModuleList (0): 5-3                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-5                                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-9                       [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-10           [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-9                     [2, 128, 32, 32]          [2, 128, 32, 32]          16,384\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-10                   [2, 128, 32, 32]          [2, 256, 8, 8]            524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-11                  [2, 128, 32, 32]          [2, 128, 32, 32]          16,384\n",
       "│    │    │    │    │    └─PreNorm (1): 6-6                                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-11                      [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-12                   [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-12                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-9                   [2, 128, 32, 32]          [2, 1024, 32, 32]         132,096\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-10                [2, 1024, 32, 32]         [2, 1024, 32, 32]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-3       [2, 1024, 32, 32]         [2, 1024, 32, 32]         1,059,840\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-11                    [2, 1024, 32, 32]         [2, 1024, 32, 32]         --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-12                  [2, 1024, 32, 32]         [2, 128, 32, 32]          131,200\n",
       "│    │    │    │    └─ModuleList (1): 5-4                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-7                                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-13                      [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-14           [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-13                    [2, 128, 32, 32]          [2, 128, 32, 32]          16,384\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-14                   [2, 128, 32, 32]          [2, 256, 8, 8]            524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-15                  [2, 128, 32, 32]          [2, 128, 32, 32]          16,384\n",
       "│    │    │    │    │    └─PreNorm (1): 6-8                                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-15                      [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-16                   [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-16                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-13                  [2, 128, 32, 32]          [2, 1024, 32, 32]         132,096\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-14                [2, 1024, 32, 32]         [2, 1024, 32, 32]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-4       [2, 1024, 32, 32]         [2, 1024, 32, 32]         1,059,840\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-15                    [2, 1024, 32, 32]         [2, 1024, 32, 32]         --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-16                  [2, 1024, 32, 32]         [2, 128, 32, 32]          131,200\n",
       "│    │    └─ModuleList (2): 3-3                                             --                        --                        --\n",
       "│    │    │    └─Unfold (0): 4-7                                            [2, 128, 32, 32]          [2, 1152, 256]            --\n",
       "│    │    │    └─Conv2d (1): 4-8                                            [2, 1152, 16, 16]         [2, 320, 16, 16]          368,960\n",
       "│    │    │    └─ModuleList (2): 4-9                                        --                        --                        --\n",
       "│    │    │    │    └─ModuleList (0): 5-5                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-9                                 [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-17                      [2, 320, 16, 16]          [2, 320, 16, 16]          640\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-18           [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-17                    [2, 320, 16, 16]          [2, 320, 16, 16]          102,400\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-18                   [2, 320, 16, 16]          [2, 640, 8, 8]            819,200\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-19                  [2, 320, 16, 16]          [2, 320, 16, 16]          102,400\n",
       "│    │    │    │    │    └─PreNorm (1): 6-10                                [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-19                      [2, 320, 16, 16]          [2, 320, 16, 16]          640\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-20                   [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-20                 [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-17                  [2, 320, 16, 16]          [2, 1280, 16, 16]         410,880\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-18                [2, 1280, 16, 16]         [2, 1280, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-5       [2, 1280, 16, 16]         [2, 1280, 16, 16]         1,652,480\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-19                    [2, 1280, 16, 16]         [2, 1280, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-20                  [2, 1280, 16, 16]         [2, 320, 16, 16]          409,920\n",
       "│    │    │    │    └─ModuleList (1): 5-6                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-11                                [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-21                      [2, 320, 16, 16]          [2, 320, 16, 16]          640\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-22           [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-21                    [2, 320, 16, 16]          [2, 320, 16, 16]          102,400\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-22                   [2, 320, 16, 16]          [2, 640, 8, 8]            819,200\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-23                  [2, 320, 16, 16]          [2, 320, 16, 16]          102,400\n",
       "│    │    │    │    │    └─PreNorm (1): 6-12                                [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-23                      [2, 320, 16, 16]          [2, 320, 16, 16]          640\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-24                   [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-24                 [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-21                  [2, 320, 16, 16]          [2, 1280, 16, 16]         410,880\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-22                [2, 1280, 16, 16]         [2, 1280, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-6       [2, 1280, 16, 16]         [2, 1280, 16, 16]         1,652,480\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-23                    [2, 1280, 16, 16]         [2, 1280, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-24                  [2, 1280, 16, 16]         [2, 320, 16, 16]          409,920\n",
       "│    │    └─ModuleList (3): 3-4                                             --                        --                        --\n",
       "│    │    │    └─Unfold (0): 4-10                                           [2, 320, 16, 16]          [2, 2880, 64]             --\n",
       "│    │    │    └─Conv2d (1): 4-11                                           [2, 2880, 8, 8]           [2, 512, 8, 8]            1,475,072\n",
       "│    │    │    └─ModuleList (2): 4-12                                       --                        --                        --\n",
       "│    │    │    │    └─ModuleList (0): 5-7                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-13                                [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-25                      [2, 512, 8, 8]            [2, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-26           [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-25                    [2, 512, 8, 8]            [2, 512, 8, 8]            262,144\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-26                   [2, 512, 8, 8]            [2, 1024, 8, 8]           524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-27                  [2, 512, 8, 8]            [2, 512, 8, 8]            262,144\n",
       "│    │    │    │    │    └─PreNorm (1): 6-14                                [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-27                      [2, 512, 8, 8]            [2, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-28                   [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-28                 [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-25                  [2, 512, 8, 8]            [2, 2048, 8, 8]           1,050,624\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-26                [2, 2048, 8, 8]           [2, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-7       [2, 2048, 8, 8]           [2, 2048, 8, 8]           4,216,832\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-27                    [2, 2048, 8, 8]           [2, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-28                  [2, 2048, 8, 8]           [2, 512, 8, 8]            1,049,088\n",
       "│    │    │    │    └─ModuleList (1): 5-8                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-15                                [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-29                      [2, 512, 8, 8]            [2, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-30           [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-29                    [2, 512, 8, 8]            [2, 512, 8, 8]            262,144\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-30                   [2, 512, 8, 8]            [2, 1024, 8, 8]           524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-31                  [2, 512, 8, 8]            [2, 512, 8, 8]            262,144\n",
       "│    │    │    │    │    └─PreNorm (1): 6-16                                [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-31                      [2, 512, 8, 8]            [2, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-32                   [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-32                 [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-29                  [2, 512, 8, 8]            [2, 2048, 8, 8]           1,050,624\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-30                [2, 2048, 8, 8]           [2, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-8       [2, 2048, 8, 8]           [2, 2048, 8, 8]           4,216,832\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-31                    [2, 2048, 8, 8]           [2, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-32                  [2, 2048, 8, 8]           [2, 512, 8, 8]            1,049,088\n",
       "├─ModuleList (to_fused): 1-2                                                --                        --                        --\n",
       "│    └─Sequential (0): 2-2                                                  [2, 64, 64, 64]           [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (0): 3-5                                                 [2, 64, 64, 64]           [2, 512, 64, 64]          33,280\n",
       "│    │    └─Upsample (1): 3-6                                               [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    └─Sequential (1): 2-3                                                  [2, 128, 32, 32]          [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (0): 3-7                                                 [2, 128, 32, 32]          [2, 512, 32, 32]          66,048\n",
       "│    │    └─Upsample (1): 3-8                                               [2, 512, 32, 32]          [2, 512, 64, 64]          --\n",
       "│    └─Sequential (2): 2-4                                                  [2, 320, 16, 16]          [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (0): 3-9                                                 [2, 320, 16, 16]          [2, 512, 16, 16]          164,352\n",
       "│    │    └─Upsample (1): 3-10                                              [2, 512, 16, 16]          [2, 512, 64, 64]          --\n",
       "│    └─Sequential (3): 2-5                                                  [2, 512, 8, 8]            [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (0): 3-11                                                [2, 512, 8, 8]            [2, 512, 8, 8]            262,656\n",
       "│    │    └─Upsample (1): 3-12                                              [2, 512, 8, 8]            [2, 512, 64, 64]          --\n",
       "├─Sequential (to_segmentation): 1-3                                         [2, 2048, 64, 64]         [2, 7, 64, 64]            --\n",
       "│    └─Conv2d (0): 2-6                                                      [2, 2048, 64, 64]         [2, 512, 64, 64]          1,049,088\n",
       "│    └─Conv2d (1): 2-7                                                      [2, 512, 64, 64]          [2, 7, 64, 64]            3,591\n",
       "├─Sequential (to_regression): 1-4                                           [2, 2048, 64, 64]         [2, 1, 64, 64]            --\n",
       "│    └─Conv2d (0): 2-8                                                      [2, 2048, 64, 64]         [2, 1024, 64, 64]         2,098,176\n",
       "│    └─GELU (1): 2-9                                                        [2, 1024, 64, 64]         [2, 1024, 64, 64]         --\n",
       "│    └─Conv2d (2): 2-10                                                     [2, 1024, 64, 64]         [2, 512, 64, 64]          524,800\n",
       "│    └─Conv2d (3): 2-11                                                     [2, 512, 64, 64]          [2, 1, 64, 64]            513\n",
       "======================================================================================================================================================\n",
       "Total params: 33,359,112\n",
       "Trainable params: 33,359,112\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 47.54\n",
       "======================================================================================================================================================\n",
       "Input size (MB): 2.10\n",
       "Forward/backward pass size (MB): 618.92\n",
       "Params size (MB): 133.44\n",
       "Estimated Total Size (MB): 754.46\n",
       "======================================================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.segformer_simple import Segformerwithcarbon\n",
    "from torchinfo import summary\n",
    "args = {\n",
    "    'dims': (64, 128, 320, 512),\n",
    "    'heads': (1, 2, 5, 8),\n",
    "    'ff_expansion': (8, 8, 4, 4),\n",
    "    'reduction_ratio': (8, 4, 2, 1),\n",
    "    'num_layers': (2,2,2,2),\n",
    "    'channels': 4,\n",
    "    'stage_kernel_stride_pad': [(4, 2, 1), \n",
    "                                   (3, 2, 1), \n",
    "                                   (3, 2, 1), \n",
    "                                   (3, 2, 1)],\n",
    "    'decoder_dim': 512,\n",
    "    'num_classes': 7\n",
    "}\n",
    "model = Segformerwithcarbon(**args)\n",
    "summary(model,col_names=(\"input_size\",\"output_size\",\"num_params\",),row_settings=('var_names','depth'), depth=10,input_size=(2, 4, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                  Input Shape               Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "UNet_carbon (UNet_carbon)                          [2, 4, 256, 256]          [2, 7, 256, 256]          --\n",
       "├─encoding_block (conv1): 1-1                      [2, 4, 256, 256]          [2, 64, 256, 256]         --\n",
       "│    └─Sequential (encoding_block): 2-1            [2, 4, 256, 256]          [2, 64, 256, 256]         --\n",
       "│    │    └─ReflectionPad2d (0): 3-1               [2, 4, 256, 256]          [2, 4, 258, 258]          --\n",
       "│    │    └─Conv2d (1): 3-2                        [2, 4, 258, 258]          [2, 64, 256, 256]         2,368\n",
       "│    │    └─PReLU (2): 3-3                         [2, 64, 256, 256]         [2, 64, 256, 256]         1\n",
       "│    │    └─BatchNorm2d (3): 3-4                   [2, 64, 256, 256]         [2, 64, 256, 256]         128\n",
       "│    │    └─ReflectionPad2d (4): 3-5               [2, 64, 256, 256]         [2, 64, 258, 258]         --\n",
       "│    │    └─Conv2d (5): 3-6                        [2, 64, 258, 258]         [2, 64, 256, 256]         36,928\n",
       "│    │    └─PReLU (6): 3-7                         [2, 64, 256, 256]         [2, 64, 256, 256]         1\n",
       "│    │    └─BatchNorm2d (7): 3-8                   [2, 64, 256, 256]         [2, 64, 256, 256]         128\n",
       "├─MaxPool2d (maxpool1): 1-2                        [2, 64, 256, 256]         [2, 64, 128, 128]         --\n",
       "├─encoding_block (conv2): 1-3                      [2, 64, 128, 128]         [2, 128, 128, 128]        --\n",
       "│    └─Sequential (encoding_block): 2-2            [2, 64, 128, 128]         [2, 128, 128, 128]        --\n",
       "│    │    └─ReflectionPad2d (0): 3-9               [2, 64, 128, 128]         [2, 64, 130, 130]         --\n",
       "│    │    └─Conv2d (1): 3-10                       [2, 64, 130, 130]         [2, 128, 128, 128]        73,856\n",
       "│    │    └─PReLU (2): 3-11                        [2, 128, 128, 128]        [2, 128, 128, 128]        1\n",
       "│    │    └─BatchNorm2d (3): 3-12                  [2, 128, 128, 128]        [2, 128, 128, 128]        256\n",
       "│    │    └─ReflectionPad2d (4): 3-13              [2, 128, 128, 128]        [2, 128, 130, 130]        --\n",
       "│    │    └─Conv2d (5): 3-14                       [2, 128, 130, 130]        [2, 128, 128, 128]        147,584\n",
       "│    │    └─PReLU (6): 3-15                        [2, 128, 128, 128]        [2, 128, 128, 128]        1\n",
       "│    │    └─BatchNorm2d (7): 3-16                  [2, 128, 128, 128]        [2, 128, 128, 128]        256\n",
       "├─MaxPool2d (maxpool2): 1-4                        [2, 128, 128, 128]        [2, 128, 64, 64]          --\n",
       "├─encoding_block (conv3): 1-5                      [2, 128, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    └─Sequential (encoding_block): 2-3            [2, 128, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─ReflectionPad2d (0): 3-17              [2, 128, 64, 64]          [2, 128, 66, 66]          --\n",
       "│    │    └─Conv2d (1): 3-18                       [2, 128, 66, 66]          [2, 256, 64, 64]          295,168\n",
       "│    │    └─PReLU (2): 3-19                        [2, 256, 64, 64]          [2, 256, 64, 64]          1\n",
       "│    │    └─BatchNorm2d (3): 3-20                  [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    └─ReflectionPad2d (4): 3-21              [2, 256, 64, 64]          [2, 256, 66, 66]          --\n",
       "│    │    └─Conv2d (5): 3-22                       [2, 256, 66, 66]          [2, 256, 64, 64]          590,080\n",
       "│    │    └─PReLU (6): 3-23                        [2, 256, 64, 64]          [2, 256, 64, 64]          1\n",
       "│    │    └─BatchNorm2d (7): 3-24                  [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "├─MaxPool2d (maxpool3): 1-6                        [2, 256, 64, 64]          [2, 256, 32, 32]          --\n",
       "├─encoding_block (conv4): 1-7                      [2, 256, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    └─Sequential (encoding_block): 2-4            [2, 256, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    └─ReflectionPad2d (0): 3-25              [2, 256, 32, 32]          [2, 256, 34, 34]          --\n",
       "│    │    └─Conv2d (1): 3-26                       [2, 256, 34, 34]          [2, 512, 32, 32]          1,180,160\n",
       "│    │    └─PReLU (2): 3-27                        [2, 512, 32, 32]          [2, 512, 32, 32]          1\n",
       "│    │    └─BatchNorm2d (3): 3-28                  [2, 512, 32, 32]          [2, 512, 32, 32]          1,024\n",
       "│    │    └─ReflectionPad2d (4): 3-29              [2, 512, 32, 32]          [2, 512, 34, 34]          --\n",
       "│    │    └─Conv2d (5): 3-30                       [2, 512, 34, 34]          [2, 512, 32, 32]          2,359,808\n",
       "│    │    └─PReLU (6): 3-31                        [2, 512, 32, 32]          [2, 512, 32, 32]          1\n",
       "│    │    └─BatchNorm2d (7): 3-32                  [2, 512, 32, 32]          [2, 512, 32, 32]          1,024\n",
       "├─MaxPool2d (maxpool4): 1-8                        [2, 512, 32, 32]          [2, 512, 16, 16]          --\n",
       "├─encoding_block (center): 1-9                     [2, 512, 16, 16]          [2, 1024, 16, 16]         --\n",
       "│    └─Sequential (encoding_block): 2-5            [2, 512, 16, 16]          [2, 1024, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d (0): 3-33              [2, 512, 16, 16]          [2, 512, 18, 18]          --\n",
       "│    │    └─Conv2d (1): 3-34                       [2, 512, 18, 18]          [2, 1024, 16, 16]         4,719,616\n",
       "│    │    └─PReLU (2): 3-35                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         1\n",
       "│    │    └─BatchNorm2d (3): 3-36                  [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    └─ReflectionPad2d (4): 3-37              [2, 1024, 16, 16]         [2, 1024, 18, 18]         --\n",
       "│    │    └─Conv2d (5): 3-38                       [2, 1024, 18, 18]         [2, 1024, 16, 16]         9,438,208\n",
       "│    │    └─PReLU (6): 3-39                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         1\n",
       "│    │    └─BatchNorm2d (7): 3-40                  [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "├─decoding_block (decode4): 1-10                   [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    └─Sequential (up): 2-6                        [2, 1024, 16, 16]         [2, 512, 32, 32]          --\n",
       "│    │    └─Upsample (0): 3-41                     [2, 1024, 16, 16]         [2, 1024, 32, 32]         --\n",
       "│    │    └─Conv2d (1): 3-42                       [2, 1024, 32, 32]         [2, 512, 32, 32]          524,800\n",
       "│    └─encoding_block (conv): 2-7                  [2, 1024, 32, 32]         [2, 512, 32, 32]          --\n",
       "│    │    └─Sequential (encoding_block): 3-43      [2, 1024, 32, 32]         [2, 512, 32, 32]          --\n",
       "│    │    │    └─ReflectionPad2d (0): 4-1          [2, 1024, 32, 32]         [2, 1024, 34, 34]         --\n",
       "│    │    │    └─Conv2d (1): 4-2                   [2, 1024, 34, 34]         [2, 512, 32, 32]          4,719,104\n",
       "│    │    │    └─PReLU (2): 4-3                    [2, 512, 32, 32]          [2, 512, 32, 32]          1\n",
       "│    │    │    └─ReflectionPad2d (3): 4-4          [2, 512, 32, 32]          [2, 512, 34, 34]          --\n",
       "│    │    │    └─Conv2d (4): 4-5                   [2, 512, 34, 34]          [2, 512, 32, 32]          2,359,808\n",
       "│    │    │    └─PReLU (5): 4-6                    [2, 512, 32, 32]          [2, 512, 32, 32]          1\n",
       "├─decoding_block (decode3): 1-11                   [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    └─Sequential (up): 2-8                        [2, 512, 32, 32]          [2, 256, 64, 64]          --\n",
       "│    │    └─Upsample (0): 3-44                     [2, 512, 32, 32]          [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (1): 3-45                       [2, 512, 64, 64]          [2, 256, 64, 64]          131,328\n",
       "│    └─encoding_block (conv): 2-9                  [2, 512, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─Sequential (encoding_block): 3-46      [2, 512, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    └─ReflectionPad2d (0): 4-7          [2, 512, 64, 64]          [2, 512, 66, 66]          --\n",
       "│    │    │    └─Conv2d (1): 4-8                   [2, 512, 66, 66]          [2, 256, 64, 64]          1,179,904\n",
       "│    │    │    └─PReLU (2): 4-9                    [2, 256, 64, 64]          [2, 256, 64, 64]          1\n",
       "│    │    │    └─ReflectionPad2d (3): 4-10         [2, 256, 64, 64]          [2, 256, 66, 66]          --\n",
       "│    │    │    └─Conv2d (4): 4-11                  [2, 256, 66, 66]          [2, 256, 64, 64]          590,080\n",
       "│    │    │    └─PReLU (5): 4-12                   [2, 256, 64, 64]          [2, 256, 64, 64]          1\n",
       "├─decoding_block (decode2): 1-12                   [2, 128, 128, 128]        [2, 128, 128, 128]        --\n",
       "│    └─Sequential (up): 2-10                       [2, 256, 64, 64]          [2, 128, 128, 128]        --\n",
       "│    │    └─Upsample (0): 3-47                     [2, 256, 64, 64]          [2, 256, 128, 128]        --\n",
       "│    │    └─Conv2d (1): 3-48                       [2, 256, 128, 128]        [2, 128, 128, 128]        32,896\n",
       "│    └─encoding_block (conv): 2-11                 [2, 256, 128, 128]        [2, 128, 128, 128]        --\n",
       "│    │    └─Sequential (encoding_block): 3-49      [2, 256, 128, 128]        [2, 128, 128, 128]        --\n",
       "│    │    │    └─ReflectionPad2d (0): 4-13         [2, 256, 128, 128]        [2, 256, 130, 130]        --\n",
       "│    │    │    └─Conv2d (1): 4-14                  [2, 256, 130, 130]        [2, 128, 128, 128]        295,040\n",
       "│    │    │    └─PReLU (2): 4-15                   [2, 128, 128, 128]        [2, 128, 128, 128]        1\n",
       "│    │    │    └─ReflectionPad2d (3): 4-16         [2, 128, 128, 128]        [2, 128, 130, 130]        --\n",
       "│    │    │    └─Conv2d (4): 4-17                  [2, 128, 130, 130]        [2, 128, 128, 128]        147,584\n",
       "│    │    │    └─PReLU (5): 4-18                   [2, 128, 128, 128]        [2, 128, 128, 128]        1\n",
       "├─decoding_block (decode1): 1-13                   [2, 64, 256, 256]         [2, 64, 256, 256]         --\n",
       "│    └─Sequential (up): 2-12                       [2, 128, 128, 128]        [2, 64, 256, 256]         --\n",
       "│    │    └─Upsample (0): 3-50                     [2, 128, 128, 128]        [2, 128, 256, 256]        --\n",
       "│    │    └─Conv2d (1): 3-51                       [2, 128, 256, 256]        [2, 64, 256, 256]         8,256\n",
       "│    └─encoding_block (conv): 2-13                 [2, 128, 256, 256]        [2, 64, 256, 256]         --\n",
       "│    │    └─Sequential (encoding_block): 3-52      [2, 128, 256, 256]        [2, 64, 256, 256]         --\n",
       "│    │    │    └─ReflectionPad2d (0): 4-19         [2, 128, 256, 256]        [2, 128, 258, 258]        --\n",
       "│    │    │    └─Conv2d (1): 4-20                  [2, 128, 258, 258]        [2, 64, 256, 256]         73,792\n",
       "│    │    │    └─PReLU (2): 4-21                   [2, 64, 256, 256]         [2, 64, 256, 256]         1\n",
       "│    │    │    └─ReflectionPad2d (3): 4-22         [2, 64, 256, 256]         [2, 64, 258, 258]         --\n",
       "│    │    │    └─Conv2d (4): 4-23                  [2, 64, 258, 258]         [2, 64, 256, 256]         36,928\n",
       "│    │    │    └─PReLU (5): 4-24                   [2, 64, 256, 256]         [2, 64, 256, 256]         1\n",
       "├─Conv2d (final_cls): 1-14                         [2, 64, 256, 256]         [2, 7, 256, 256]          455\n",
       "├─Conv2d (final_reg): 1-15                         [2, 64, 256, 256]         [2, 1, 256, 256]          65\n",
       "=============================================================================================================================\n",
       "Total params: 28,951,770\n",
       "Trainable params: 28,951,770\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 96.55\n",
       "=============================================================================================================================\n",
       "Input size (MB): 2.10\n",
       "Forward/backward pass size (MB): 1417.67\n",
       "Params size (MB): 115.81\n",
       "Estimated Total Size (MB): 1535.58\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from models.unet import UNet_carbon\n",
    "\n",
    "model = UNet_carbon(num_classes=7)\n",
    "summary(model,col_names=(\"input_size\",\"output_size\",\"num_params\",),row_settings=('var_names','depth'), depth=10,input_size=(2, 4, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                                      Input Shape               Output Shape              Param #\n",
       "=================================================================================================================================================\n",
       "DPTSegmentationModel (DPTSegmentationModel)                            [2, 3, 256, 256]          [2, 4, 256, 256]          591,364\n",
       "├─Module (pretrained): 1-1                                             --                        --                        --\n",
       "│    └─VisionTransformer (model): 2-1                                  --                        --                        1,616,872\n",
       "│    │    └─PatchEmbed (patch_embed): 3-1                              --                        --                        --\n",
       "│    │    │    └─Conv2d (proj): 4-1                                    [2, 3, 256, 256]          [2, 1024, 16, 16]         787,456\n",
       "│    │    └─Dropout (pos_drop): 3-2                                    [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    └─Sequential (blocks): 3-3                                   --                        --                        --\n",
       "│    │    │    └─Block (0): 4-2                                        [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-1                           [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-2                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-1                           [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-2                      [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-3                      [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-4                          [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-5                    [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-3                              [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-4                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-5                           [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-6                                   [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-6                           [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-7                             [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-8                        [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-9                        [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-10                          [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-11                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-7                              [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-8                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (1): 4-3                                        [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-9                           [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-10                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-12                          [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-13                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-14                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-15                         [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-16                   [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-11                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-12                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-13                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-14                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-17                          [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-18                            [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-19                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-20                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-21                          [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-22                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-15                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-16                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (2): 4-4                                        [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-17                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-18                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-23                          [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-24                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-25                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-26                         [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-27                   [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-19                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-20                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-21                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-22                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-28                          [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-29                            [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-30                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-31                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-32                          [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-33                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-23                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-24                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (3): 4-5                                        [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-25                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-26                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-34                          [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-35                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-36                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-37                         [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-38                   [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-27                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-28                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-29                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-30                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-39                          [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-40                            [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-41                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-42                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-43                          [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-44                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-31                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-32                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (4): 4-6                                        [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-33                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-34                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-45                          [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-46                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-47                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-48                         [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-49                   [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-35                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-36                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-37                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-38                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-50                          [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-51                            [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-52                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-53                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-54                          [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-55                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-39                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-40                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (5): 4-7                                        [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-41                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-42                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-56                          [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-57                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-58                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-59                         [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-60                   [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-43                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-44                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-45                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-46                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-61                          [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-62                            [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-63                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-64                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-65                          [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-66                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-47                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-48                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (6): 4-8                                        [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-49                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-50                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-67                          [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-68                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-69                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-70                         [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-71                   [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-51                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-52                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-53                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-54                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-72                          [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-73                            [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-74                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-75                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-76                          [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-77                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-55                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-56                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (7): 4-9                                        [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-57                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-58                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-78                          [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-79                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-80                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-81                         [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-82                   [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-59                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-60                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-61                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-62                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-83                          [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-84                            [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-85                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-86                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-87                          [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-88                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-63                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-64                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (8): 4-10                                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-65                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-66                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-89                          [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-90                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-91                     [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-92                         [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-93                   [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-67                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-68                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-69                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-70                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-94                          [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-95                            [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-96                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-97                       [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-98                          [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-99                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-71                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-72                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (9): 4-11                                       [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-73                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-74                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-100                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-101                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-102                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-103                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-104                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-75                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-76                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-77                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-78                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-105                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-106                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-107                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-108                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-109                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-110                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-79                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-80                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (10): 4-12                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-81                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-82                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-111                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-112                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-113                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-114                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-115                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-83                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-84                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-85                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-86                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-116                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-117                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-118                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-119                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-120                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-121                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-87                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-88                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (11): 4-13                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-89                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-90                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-122                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-123                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-124                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-125                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-126                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-91                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-92                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-93                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-94                                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-127                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-128                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-129                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-130                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-131                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-132                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-95                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-96                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (12): 4-14                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-97                          [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-98                           [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-133                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-134                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-135                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-136                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-137                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-99                             [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-100                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-101                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-102                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-138                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-139                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-140                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-141                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-142                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-143                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-103                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-104                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (13): 4-15                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-105                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-106                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-144                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-145                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-146                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-147                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-148                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-107                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-108                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-109                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-110                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-149                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-150                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-151                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-152                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-153                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-154                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-111                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-112                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (14): 4-16                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-113                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-114                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-155                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-156                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-157                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-158                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-159                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-115                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-116                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-117                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-118                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-160                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-161                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-162                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-163                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-164                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-165                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-119                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-120                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (15): 4-17                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-121                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-122                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-166                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-167                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-168                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-169                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-170                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-123                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-124                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-125                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-126                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-171                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-172                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-173                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-174                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-175                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-176                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-127                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-128                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (16): 4-18                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-129                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-130                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-177                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-178                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-179                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-180                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-181                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-131                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-132                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-133                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-134                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-182                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-183                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-184                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-185                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-186                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-187                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-135                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-136                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (17): 4-19                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-137                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-138                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-188                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-189                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-190                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-191                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-192                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-139                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-140                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-141                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-142                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-193                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-194                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-195                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-196                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-197                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-198                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-143                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-144                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (18): 4-20                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-145                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-146                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-199                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-200                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-201                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-202                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-203                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-147                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-148                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-149                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-150                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-204                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-205                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-206                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-207                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-208                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-209                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-151                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-152                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (19): 4-21                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-153                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-154                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-210                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-211                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-212                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-213                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-214                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-155                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-156                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-157                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-158                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-215                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-216                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-217                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-218                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-219                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-220                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-159                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-160                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (20): 4-22                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-161                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-162                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-221                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-222                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-223                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-224                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-225                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-163                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-164                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-165                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-166                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-226                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-227                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-228                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-229                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-230                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-231                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-167                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-168                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (21): 4-23                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-169                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-170                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-232                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-233                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-234                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-235                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-236                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-171                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-172                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-173                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-174                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-237                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-238                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-239                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-240                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-241                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-242                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-175                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-176                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (22): 4-24                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-177                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-178                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-243                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-244                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-245                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-246                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-247                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-179                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-180                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-181                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-182                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-248                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-249                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-250                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-251                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-252                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-253                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-183                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-184                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    └─Block (23): 4-25                                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-185                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Attention (attn): 5-186                          [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-254                         [2, 257, 1024]            [2, 257, 3072]            3,148,800\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-255                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-256                    [2, 16, 257, 64]          [2, 16, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-257                        [2, 257, 1024]            [2, 257, 1024]            1,049,600\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-258                  [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls1): 5-187                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-188                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-189                         [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    │    │    │    └─Mlp (mlp): 5-190                                 [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-259                         [2, 257, 1024]            [2, 257, 4096]            4,198,400\n",
       "│    │    │    │    │    └─GELU (act): 6-260                           [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-261                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-262                      [2, 257, 4096]            [2, 257, 4096]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-263                         [2, 257, 4096]            [2, 257, 1024]            4,195,328\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-264                      [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (ls2): 5-191                            [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-192                     [2, 257, 1024]            [2, 257, 1024]            --\n",
       "│    │    └─LayerNorm (norm): 3-4                                      [2, 257, 1024]            [2, 257, 1024]            2,048\n",
       "│    └─Sequential (act_postprocess1): 2-6                              --                        --                        (recursive)\n",
       "│    │    └─ProjectReadout (0): 3-5                                    [2, 257, 1024]            [2, 256, 1024]            --\n",
       "│    │    │    └─Sequential (project): 4-26                            [2, 256, 2048]            [2, 256, 1024]            --\n",
       "│    │    │    │    └─Linear (0): 5-193                                [2, 256, 2048]            [2, 256, 1024]            2,098,176\n",
       "│    │    │    │    └─GELU (1): 5-194                                  [2, 256, 1024]            [2, 256, 1024]            --\n",
       "│    │    └─Transpose (1): 3-6                                         [2, 256, 1024]            [2, 1024, 256]            --\n",
       "│    └─Sequential (act_postprocess2): 2-7                              --                        --                        (recursive)\n",
       "│    │    └─ProjectReadout (0): 3-7                                    [2, 257, 1024]            [2, 256, 1024]            --\n",
       "│    │    │    └─Sequential (project): 4-27                            [2, 256, 2048]            [2, 256, 1024]            --\n",
       "│    │    │    │    └─Linear (0): 5-195                                [2, 256, 2048]            [2, 256, 1024]            2,098,176\n",
       "│    │    │    │    └─GELU (1): 5-196                                  [2, 256, 1024]            [2, 256, 1024]            --\n",
       "│    │    └─Transpose (1): 3-8                                         [2, 256, 1024]            [2, 1024, 256]            --\n",
       "│    └─Sequential (act_postprocess3): 2-8                              --                        --                        (recursive)\n",
       "│    │    └─ProjectReadout (0): 3-9                                    [2, 257, 1024]            [2, 256, 1024]            --\n",
       "│    │    │    └─Sequential (project): 4-28                            [2, 256, 2048]            [2, 256, 1024]            --\n",
       "│    │    │    │    └─Linear (0): 5-197                                [2, 256, 2048]            [2, 256, 1024]            2,098,176\n",
       "│    │    │    │    └─GELU (1): 5-198                                  [2, 256, 1024]            [2, 256, 1024]            --\n",
       "│    │    └─Transpose (1): 3-10                                        [2, 256, 1024]            [2, 1024, 256]            --\n",
       "│    └─Sequential (act_postprocess4): 2-9                              --                        --                        (recursive)\n",
       "│    │    └─ProjectReadout (0): 3-11                                   [2, 257, 1024]            [2, 256, 1024]            --\n",
       "│    │    │    └─Sequential (project): 4-29                            [2, 256, 2048]            [2, 256, 1024]            --\n",
       "│    │    │    │    └─Linear (0): 5-199                                [2, 256, 2048]            [2, 256, 1024]            2,098,176\n",
       "│    │    │    │    └─GELU (1): 5-200                                  [2, 256, 1024]            [2, 256, 1024]            --\n",
       "│    │    └─Transpose (1): 3-12                                        [2, 256, 1024]            [2, 1024, 256]            --\n",
       "│    └─Sequential (act_postprocess1): 2-6                              --                        --                        (recursive)\n",
       "│    │    └─Conv2d (3): 3-13                                           [2, 1024, 16, 16]         [2, 256, 16, 16]          262,400\n",
       "│    │    └─ConvTranspose2d (4): 3-14                                  [2, 256, 16, 16]          [2, 256, 64, 64]          1,048,832\n",
       "│    └─Sequential (act_postprocess2): 2-7                              --                        --                        (recursive)\n",
       "│    │    └─Conv2d (3): 3-15                                           [2, 1024, 16, 16]         [2, 512, 16, 16]          524,800\n",
       "│    │    └─ConvTranspose2d (4): 3-16                                  [2, 512, 16, 16]          [2, 512, 32, 32]          1,049,088\n",
       "│    └─Sequential (act_postprocess3): 2-8                              --                        --                        (recursive)\n",
       "│    │    └─Conv2d (3): 3-17                                           [2, 1024, 16, 16]         [2, 1024, 16, 16]         1,049,600\n",
       "│    └─Sequential (act_postprocess4): 2-9                              --                        --                        (recursive)\n",
       "│    │    └─Conv2d (3): 3-18                                           [2, 1024, 16, 16]         [2, 1024, 16, 16]         1,049,600\n",
       "│    │    └─Conv2d (4): 3-19                                           [2, 1024, 16, 16]         [2, 1024, 8, 8]           9,438,208\n",
       "├─Module (scratch): 1-2                                                --                        --                        --\n",
       "│    └─Conv2d (layer1_rn): 2-10                                        [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    └─Conv2d (layer2_rn): 2-11                                        [2, 512, 32, 32]          [2, 256, 32, 32]          1,179,648\n",
       "│    └─Conv2d (layer3_rn): 2-12                                        [2, 1024, 16, 16]         [2, 256, 16, 16]          2,359,296\n",
       "│    └─Conv2d (layer4_rn): 2-13                                        [2, 1024, 8, 8]           [2, 256, 8, 8]            2,359,296\n",
       "│    └─FeatureFusionBlock_custom (refinenet4): 2-14                    [2, 256, 8, 8]            [2, 256, 16, 16]          1,180,672\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-20               [2, 256, 8, 8]            [2, 256, 8, 8]            --\n",
       "│    │    │    └─ReLU (activation): 4-30                               [2, 256, 8, 8]            [2, 256, 8, 8]            --\n",
       "│    │    │    └─Conv2d (conv1): 4-31                                  [2, 256, 8, 8]            [2, 256, 8, 8]            589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-32                               [2, 256, 8, 8]            [2, 256, 8, 8]            512\n",
       "│    │    │    └─ReLU (activation): 4-33                               [2, 256, 8, 8]            [2, 256, 8, 8]            --\n",
       "│    │    │    └─Conv2d (conv2): 4-34                                  [2, 256, 8, 8]            [2, 256, 8, 8]            589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-35                               [2, 256, 8, 8]            [2, 256, 8, 8]            512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-36                      --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-201        [2, 256, 8, 8]            [2, 256, 8, 8]            --\n",
       "│    │    └─Conv2d (out_conv): 3-21                                    [2, 256, 16, 16]          [2, 256, 16, 16]          65,792\n",
       "│    └─FeatureFusionBlock_custom (refinenet3): 2-15                    [2, 256, 16, 16]          [2, 256, 32, 32]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-22               [2, 256, 16, 16]          [2, 256, 16, 16]          1,180,672\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-25               --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-37                               [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-26               --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv1): 4-38                                  [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-39                               [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-25               --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-40                               [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-26               --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv2): 4-41                                  [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-42                               [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-43                      --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-202        [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─FloatFunctional (skip_add): 3-27                           --                        --                        --\n",
       "│    │    │    └─Identity (activation_post_process): 4-44              [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-28               [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    └─ReLU (activation): 4-45                               [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d (conv1): 4-46                                  [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-47                               [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU (activation): 4-48                               [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d (conv2): 4-49                                  [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-50                               [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-51                      --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-203        [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (out_conv): 3-29                                    [2, 256, 32, 32]          [2, 256, 32, 32]          65,792\n",
       "│    └─FeatureFusionBlock_custom (refinenet2): 2-16                    [2, 256, 32, 32]          [2, 256, 64, 64]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-30               [2, 256, 32, 32]          [2, 256, 32, 32]          1,180,672\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-33               --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-52                               [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-34               --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv1): 4-53                                  [2, 256, 32, 32]          [2, 256, 32, 32]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-54                               [2, 256, 32, 32]          [2, 256, 32, 32]          512\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-33               --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-55                               [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-34               --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv2): 4-56                                  [2, 256, 32, 32]          [2, 256, 32, 32]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-57                               [2, 256, 32, 32]          [2, 256, 32, 32]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-58                      --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-204        [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─FloatFunctional (skip_add): 3-35                           --                        --                        --\n",
       "│    │    │    └─Identity (activation_post_process): 4-59              [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-36               [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    │    └─ReLU (activation): 4-60                               [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    │    └─Conv2d (conv1): 4-61                                  [2, 256, 32, 32]          [2, 256, 32, 32]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-62                               [2, 256, 32, 32]          [2, 256, 32, 32]          512\n",
       "│    │    │    └─ReLU (activation): 4-63                               [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    │    └─Conv2d (conv2): 4-64                                  [2, 256, 32, 32]          [2, 256, 32, 32]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-65                               [2, 256, 32, 32]          [2, 256, 32, 32]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-66                      --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-205        [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─Conv2d (out_conv): 3-37                                    [2, 256, 64, 64]          [2, 256, 64, 64]          65,792\n",
       "│    └─FeatureFusionBlock_custom (refinenet1): 2-17                    [2, 256, 64, 64]          [2, 256, 128, 128]        --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-38               [2, 256, 64, 64]          [2, 256, 64, 64]          1,180,672\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-41               --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-67                               [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-42               --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv1): 4-68                                  [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-69                               [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-41               --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-70                               [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-42               --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv2): 4-71                                  [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-72                               [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-73                      --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-206        [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─FloatFunctional (skip_add): 3-43                           --                        --                        --\n",
       "│    │    │    └─Identity (activation_post_process): 4-74              [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-44               [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    └─ReLU (activation): 4-75                               [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    └─Conv2d (conv1): 4-76                                  [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-77                               [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    └─ReLU (activation): 4-78                               [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    └─Conv2d (conv2): 4-79                                  [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-80                               [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-81                      --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-207        [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─Conv2d (out_conv): 3-45                                    [2, 256, 128, 128]        [2, 256, 128, 128]        65,792\n",
       "│    └─Sequential (output_conv): 2-18                                  [2, 256, 128, 128]        [2, 4, 256, 256]          --\n",
       "│    │    └─Conv2d (0): 3-46                                           [2, 256, 128, 128]        [2, 256, 128, 128]        589,824\n",
       "│    │    └─BatchNorm2d (1): 3-47                                      [2, 256, 128, 128]        [2, 256, 128, 128]        512\n",
       "│    │    └─ReLU (2): 3-48                                             [2, 256, 128, 128]        [2, 256, 128, 128]        --\n",
       "│    │    └─Dropout (3): 3-49                                          [2, 256, 128, 128]        [2, 256, 128, 128]        --\n",
       "│    │    └─Conv2d (4): 3-50                                           [2, 256, 128, 128]        [2, 4, 128, 128]          1,028\n",
       "│    │    └─Interpolate (5): 3-51                                      [2, 4, 128, 128]          [2, 4, 256, 256]          --\n",
       "=================================================================================================================================================\n",
       "Total params: 348,452,336\n",
       "Trainable params: 348,452,336\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 70.95\n",
       "=================================================================================================================================================\n",
       "Input size (MB): 1.57\n",
       "Forward/backward pass size (MB): 1598.44\n",
       "Params size (MB): 1366.09\n",
       "Estimated Total Size (MB): 2966.10\n",
       "================================================================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.dpt import DPTSegmentationModel\n",
    "\n",
    "model = DPTSegmentationModel(backbone = \"vitl16_384\",num_classes=4)\n",
    "summary(model,col_names=(\"input_size\",\"output_size\",\"num_params\",),row_settings=('var_names','depth'), depth=10,input_size=(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
