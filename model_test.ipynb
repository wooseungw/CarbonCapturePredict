{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                                           Input Shape               Output Shape              Param #\n",
       "======================================================================================================================================================\n",
       "Segformerwithcarbon (Segformerwithcarbon)                                   [2, 4, 256, 256]          [2, 7, 64, 64]            --\n",
       "├─MiT (mit): 1-1                                                            [2, 4, 256, 256]          [2, 64, 64, 64]           --\n",
       "│    └─ModuleList (stages): 2-1                                             --                        --                        --\n",
       "│    │    └─ModuleList (0): 3-1                                             --                        --                        --\n",
       "│    │    │    └─Unfold (0): 4-1                                            [2, 4, 256, 256]          [2, 196, 4096]            --\n",
       "│    │    │    └─Conv2d (1): 4-2                                            [2, 196, 64, 64]          [2, 64, 64, 64]           12,608\n",
       "│    │    │    └─ModuleList (2): 4-3                                        --                        --                        --\n",
       "│    │    │    │    └─ModuleList (0): 5-1                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-1                                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-1                       [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-2            [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-1                     [2, 64, 64, 64]           [2, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-2                    [2, 64, 64, 64]           [2, 128, 8, 8]            524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-3                   [2, 64, 64, 64]           [2, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    └─PreNorm (1): 6-2                                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-3                       [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-4                    [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-4                  [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-1                   [2, 64, 64, 64]           [2, 512, 64, 64]          33,280\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-2                 [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-1       [2, 512, 64, 64]          [2, 512, 64, 64]          267,776\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-3                     [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-4                   [2, 512, 64, 64]          [2, 64, 64, 64]           32,832\n",
       "│    │    │    │    └─ModuleList (1): 5-2                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-3                                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-5                       [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-6            [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-5                     [2, 64, 64, 64]           [2, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-6                    [2, 64, 64, 64]           [2, 128, 8, 8]            524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-7                   [2, 64, 64, 64]           [2, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    └─PreNorm (1): 6-4                                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-7                       [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-8                    [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-8                  [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-5                   [2, 64, 64, 64]           [2, 512, 64, 64]          33,280\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-6                 [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-2       [2, 512, 64, 64]          [2, 512, 64, 64]          267,776\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-7                     [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-8                   [2, 512, 64, 64]          [2, 64, 64, 64]           32,832\n",
       "│    │    └─ModuleList (1): 3-2                                             --                        --                        --\n",
       "│    │    │    └─Unfold (0): 4-4                                            [2, 64, 64, 64]           [2, 576, 1024]            --\n",
       "│    │    │    └─Conv2d (1): 4-5                                            [2, 576, 32, 32]          [2, 128, 32, 32]          73,856\n",
       "│    │    │    └─ModuleList (2): 4-6                                        --                        --                        --\n",
       "│    │    │    │    └─ModuleList (0): 5-3                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-5                                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-9                       [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-10           [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-9                     [2, 128, 32, 32]          [2, 128, 32, 32]          16,384\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-10                   [2, 128, 32, 32]          [2, 256, 8, 8]            524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-11                  [2, 128, 32, 32]          [2, 128, 32, 32]          16,384\n",
       "│    │    │    │    │    └─PreNorm (1): 6-6                                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-11                      [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-12                   [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-12                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-9                   [2, 128, 32, 32]          [2, 1024, 32, 32]         132,096\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-10                [2, 1024, 32, 32]         [2, 1024, 32, 32]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-3       [2, 1024, 32, 32]         [2, 1024, 32, 32]         1,059,840\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-11                    [2, 1024, 32, 32]         [2, 1024, 32, 32]         --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-12                  [2, 1024, 32, 32]         [2, 128, 32, 32]          131,200\n",
       "│    │    │    │    └─ModuleList (1): 5-4                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-7                                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-13                      [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-14           [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-13                    [2, 128, 32, 32]          [2, 128, 32, 32]          16,384\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-14                   [2, 128, 32, 32]          [2, 256, 8, 8]            524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-15                  [2, 128, 32, 32]          [2, 128, 32, 32]          16,384\n",
       "│    │    │    │    │    └─PreNorm (1): 6-8                                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-15                      [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-16                   [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-16                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-13                  [2, 128, 32, 32]          [2, 1024, 32, 32]         132,096\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-14                [2, 1024, 32, 32]         [2, 1024, 32, 32]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-4       [2, 1024, 32, 32]         [2, 1024, 32, 32]         1,059,840\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-15                    [2, 1024, 32, 32]         [2, 1024, 32, 32]         --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-16                  [2, 1024, 32, 32]         [2, 128, 32, 32]          131,200\n",
       "│    │    └─ModuleList (2): 3-3                                             --                        --                        --\n",
       "│    │    │    └─Unfold (0): 4-7                                            [2, 128, 32, 32]          [2, 1152, 256]            --\n",
       "│    │    │    └─Conv2d (1): 4-8                                            [2, 1152, 16, 16]         [2, 320, 16, 16]          368,960\n",
       "│    │    │    └─ModuleList (2): 4-9                                        --                        --                        --\n",
       "│    │    │    │    └─ModuleList (0): 5-5                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-9                                 [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-17                      [2, 320, 16, 16]          [2, 320, 16, 16]          640\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-18           [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-17                    [2, 320, 16, 16]          [2, 320, 16, 16]          102,400\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-18                   [2, 320, 16, 16]          [2, 640, 8, 8]            819,200\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-19                  [2, 320, 16, 16]          [2, 320, 16, 16]          102,400\n",
       "│    │    │    │    │    └─PreNorm (1): 6-10                                [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-19                      [2, 320, 16, 16]          [2, 320, 16, 16]          640\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-20                   [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-20                 [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-17                  [2, 320, 16, 16]          [2, 1280, 16, 16]         410,880\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-18                [2, 1280, 16, 16]         [2, 1280, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-5       [2, 1280, 16, 16]         [2, 1280, 16, 16]         1,652,480\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-19                    [2, 1280, 16, 16]         [2, 1280, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-20                  [2, 1280, 16, 16]         [2, 320, 16, 16]          409,920\n",
       "│    │    │    │    └─ModuleList (1): 5-6                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-11                                [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-21                      [2, 320, 16, 16]          [2, 320, 16, 16]          640\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-22           [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-21                    [2, 320, 16, 16]          [2, 320, 16, 16]          102,400\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-22                   [2, 320, 16, 16]          [2, 640, 8, 8]            819,200\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-23                  [2, 320, 16, 16]          [2, 320, 16, 16]          102,400\n",
       "│    │    │    │    │    └─PreNorm (1): 6-12                                [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-23                      [2, 320, 16, 16]          [2, 320, 16, 16]          640\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-24                   [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-24                 [2, 320, 16, 16]          [2, 320, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-21                  [2, 320, 16, 16]          [2, 1280, 16, 16]         410,880\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-22                [2, 1280, 16, 16]         [2, 1280, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-6       [2, 1280, 16, 16]         [2, 1280, 16, 16]         1,652,480\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-23                    [2, 1280, 16, 16]         [2, 1280, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-24                  [2, 1280, 16, 16]         [2, 320, 16, 16]          409,920\n",
       "│    │    └─ModuleList (3): 3-4                                             --                        --                        --\n",
       "│    │    │    └─Unfold (0): 4-10                                           [2, 320, 16, 16]          [2, 2880, 64]             --\n",
       "│    │    │    └─Conv2d (1): 4-11                                           [2, 2880, 8, 8]           [2, 512, 8, 8]            1,475,072\n",
       "│    │    │    └─ModuleList (2): 4-12                                       --                        --                        --\n",
       "│    │    │    │    └─ModuleList (0): 5-7                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-13                                [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-25                      [2, 512, 8, 8]            [2, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-26           [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-25                    [2, 512, 8, 8]            [2, 512, 8, 8]            262,144\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-26                   [2, 512, 8, 8]            [2, 1024, 8, 8]           524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-27                  [2, 512, 8, 8]            [2, 512, 8, 8]            262,144\n",
       "│    │    │    │    │    └─PreNorm (1): 6-14                                [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-27                      [2, 512, 8, 8]            [2, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-28                   [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-28                 [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-25                  [2, 512, 8, 8]            [2, 2048, 8, 8]           1,050,624\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-26                [2, 2048, 8, 8]           [2, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-7       [2, 2048, 8, 8]           [2, 2048, 8, 8]           4,216,832\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-27                    [2, 2048, 8, 8]           [2, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-28                  [2, 2048, 8, 8]           [2, 512, 8, 8]            1,049,088\n",
       "│    │    │    │    └─ModuleList (1): 5-8                                   --                        --                        --\n",
       "│    │    │    │    │    └─PreNorm (0): 6-15                                [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-29                      [2, 512, 8, 8]            [2, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    └─EfficientSelfAttention (fn): 7-30           [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_q): 8-29                    [2, 512, 8, 8]            [2, 512, 8, 8]            262,144\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_kv): 8-30                   [2, 512, 8, 8]            [2, 1024, 8, 8]           524,288\n",
       "│    │    │    │    │    │    │    └─Conv2d (to_out): 8-31                  [2, 512, 8, 8]            [2, 512, 8, 8]            262,144\n",
       "│    │    │    │    │    └─PreNorm (1): 6-16                                [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    └─LayerNorm (norm): 7-31                      [2, 512, 8, 8]            [2, 512, 8, 8]            1,024\n",
       "│    │    │    │    │    │    └─MixFeedForward (fn): 7-32                   [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    └─Sequential (net): 8-32                 [2, 512, 8, 8]            [2, 512, 8, 8]            --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (0): 9-29                  [2, 512, 8, 8]            [2, 2048, 8, 8]           1,050,624\n",
       "│    │    │    │    │    │    │    │    └─DsConv2d (1): 9-30                [2, 2048, 8, 8]           [2, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    │    │    └─Sequential (net): 10-8       [2, 2048, 8, 8]           [2, 2048, 8, 8]           4,216,832\n",
       "│    │    │    │    │    │    │    │    └─GELU (2): 9-31                    [2, 2048, 8, 8]           [2, 2048, 8, 8]           --\n",
       "│    │    │    │    │    │    │    │    └─Conv2d (3): 9-32                  [2, 2048, 8, 8]           [2, 512, 8, 8]            1,049,088\n",
       "├─ModuleList (to_fused): 1-2                                                --                        --                        --\n",
       "│    └─Sequential (0): 2-2                                                  [2, 64, 64, 64]           [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (0): 3-5                                                 [2, 64, 64, 64]           [2, 512, 64, 64]          33,280\n",
       "│    │    └─Upsample (1): 3-6                                               [2, 512, 64, 64]          [2, 512, 64, 64]          --\n",
       "│    └─Sequential (1): 2-3                                                  [2, 128, 32, 32]          [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (0): 3-7                                                 [2, 128, 32, 32]          [2, 512, 32, 32]          66,048\n",
       "│    │    └─Upsample (1): 3-8                                               [2, 512, 32, 32]          [2, 512, 64, 64]          --\n",
       "│    └─Sequential (2): 2-4                                                  [2, 320, 16, 16]          [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (0): 3-9                                                 [2, 320, 16, 16]          [2, 512, 16, 16]          164,352\n",
       "│    │    └─Upsample (1): 3-10                                              [2, 512, 16, 16]          [2, 512, 64, 64]          --\n",
       "│    └─Sequential (3): 2-5                                                  [2, 512, 8, 8]            [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (0): 3-11                                                [2, 512, 8, 8]            [2, 512, 8, 8]            262,656\n",
       "│    │    └─Upsample (1): 3-12                                              [2, 512, 8, 8]            [2, 512, 64, 64]          --\n",
       "├─Sequential (to_segmentation): 1-3                                         [2, 2048, 64, 64]         [2, 7, 64, 64]            --\n",
       "│    └─Conv2d (0): 2-6                                                      [2, 2048, 64, 64]         [2, 512, 64, 64]          1,049,088\n",
       "│    └─Conv2d (1): 2-7                                                      [2, 512, 64, 64]          [2, 7, 64, 64]            3,591\n",
       "├─Sequential (to_regression): 1-4                                           [2, 2048, 64, 64]         [2, 1, 64, 64]            --\n",
       "│    └─Conv2d (0): 2-8                                                      [2, 2048, 64, 64]         [2, 1024, 64, 64]         2,098,176\n",
       "│    └─GELU (1): 2-9                                                        [2, 1024, 64, 64]         [2, 1024, 64, 64]         --\n",
       "│    └─Conv2d (2): 2-10                                                     [2, 1024, 64, 64]         [2, 512, 64, 64]          524,800\n",
       "│    └─Conv2d (3): 2-11                                                     [2, 512, 64, 64]          [2, 1, 64, 64]            513\n",
       "======================================================================================================================================================\n",
       "Total params: 33,359,112\n",
       "Trainable params: 33,359,112\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 47.54\n",
       "======================================================================================================================================================\n",
       "Input size (MB): 2.10\n",
       "Forward/backward pass size (MB): 618.92\n",
       "Params size (MB): 133.44\n",
       "Estimated Total Size (MB): 754.46\n",
       "======================================================================================================================================================"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.segformer_simple import Segformerwithcarbon\n",
    "from torchinfo import summary\n",
    "args = {\n",
    "    'dims': (64, 128, 320, 512),\n",
    "    'heads': (1, 2, 5, 8),\n",
    "    'ff_expansion': (8, 8, 4, 4),\n",
    "    'reduction_ratio': (8, 4, 2, 1),\n",
    "    'num_layers': (2,2,2,2),\n",
    "    'channels': 4,\n",
    "    'stage_kernel_stride_pad': [(4, 2, 1), \n",
    "                                   (3, 2, 1), \n",
    "                                   (3, 2, 1), \n",
    "                                   (3, 2, 1)],\n",
    "    'decoder_dim': 512,\n",
    "    'num_classes': 7\n",
    "}\n",
    "model = Segformerwithcarbon(**args)\n",
    "summary(model,col_names=(\"input_size\",\"output_size\",\"num_params\",),row_settings=('var_names','depth'), depth=10,input_size=(2, 4, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                  Input Shape               Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "UNet_carbon (UNet_carbon)                          [2, 4, 256, 256]          [2, 7, 256, 256]          --\n",
       "├─encoding_block (conv1): 1-1                      [2, 4, 256, 256]          [2, 64, 256, 256]         --\n",
       "│    └─Sequential (encoding_block): 2-1            [2, 4, 256, 256]          [2, 64, 256, 256]         --\n",
       "│    │    └─ReflectionPad2d (0): 3-1               [2, 4, 256, 256]          [2, 4, 258, 258]          --\n",
       "│    │    └─Conv2d (1): 3-2                        [2, 4, 258, 258]          [2, 64, 256, 256]         2,368\n",
       "│    │    └─PReLU (2): 3-3                         [2, 64, 256, 256]         [2, 64, 256, 256]         1\n",
       "│    │    └─BatchNorm2d (3): 3-4                   [2, 64, 256, 256]         [2, 64, 256, 256]         128\n",
       "│    │    └─ReflectionPad2d (4): 3-5               [2, 64, 256, 256]         [2, 64, 258, 258]         --\n",
       "│    │    └─Conv2d (5): 3-6                        [2, 64, 258, 258]         [2, 64, 256, 256]         36,928\n",
       "│    │    └─PReLU (6): 3-7                         [2, 64, 256, 256]         [2, 64, 256, 256]         1\n",
       "│    │    └─BatchNorm2d (7): 3-8                   [2, 64, 256, 256]         [2, 64, 256, 256]         128\n",
       "├─MaxPool2d (maxpool1): 1-2                        [2, 64, 256, 256]         [2, 64, 128, 128]         --\n",
       "├─encoding_block (conv2): 1-3                      [2, 64, 128, 128]         [2, 128, 128, 128]        --\n",
       "│    └─Sequential (encoding_block): 2-2            [2, 64, 128, 128]         [2, 128, 128, 128]        --\n",
       "│    │    └─ReflectionPad2d (0): 3-9               [2, 64, 128, 128]         [2, 64, 130, 130]         --\n",
       "│    │    └─Conv2d (1): 3-10                       [2, 64, 130, 130]         [2, 128, 128, 128]        73,856\n",
       "│    │    └─PReLU (2): 3-11                        [2, 128, 128, 128]        [2, 128, 128, 128]        1\n",
       "│    │    └─BatchNorm2d (3): 3-12                  [2, 128, 128, 128]        [2, 128, 128, 128]        256\n",
       "│    │    └─ReflectionPad2d (4): 3-13              [2, 128, 128, 128]        [2, 128, 130, 130]        --\n",
       "│    │    └─Conv2d (5): 3-14                       [2, 128, 130, 130]        [2, 128, 128, 128]        147,584\n",
       "│    │    └─PReLU (6): 3-15                        [2, 128, 128, 128]        [2, 128, 128, 128]        1\n",
       "│    │    └─BatchNorm2d (7): 3-16                  [2, 128, 128, 128]        [2, 128, 128, 128]        256\n",
       "├─MaxPool2d (maxpool2): 1-4                        [2, 128, 128, 128]        [2, 128, 64, 64]          --\n",
       "├─encoding_block (conv3): 1-5                      [2, 128, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    └─Sequential (encoding_block): 2-3            [2, 128, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─ReflectionPad2d (0): 3-17              [2, 128, 64, 64]          [2, 128, 66, 66]          --\n",
       "│    │    └─Conv2d (1): 3-18                       [2, 128, 66, 66]          [2, 256, 64, 64]          295,168\n",
       "│    │    └─PReLU (2): 3-19                        [2, 256, 64, 64]          [2, 256, 64, 64]          1\n",
       "│    │    └─BatchNorm2d (3): 3-20                  [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    └─ReflectionPad2d (4): 3-21              [2, 256, 64, 64]          [2, 256, 66, 66]          --\n",
       "│    │    └─Conv2d (5): 3-22                       [2, 256, 66, 66]          [2, 256, 64, 64]          590,080\n",
       "│    │    └─PReLU (6): 3-23                        [2, 256, 64, 64]          [2, 256, 64, 64]          1\n",
       "│    │    └─BatchNorm2d (7): 3-24                  [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "├─MaxPool2d (maxpool3): 1-6                        [2, 256, 64, 64]          [2, 256, 32, 32]          --\n",
       "├─encoding_block (conv4): 1-7                      [2, 256, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    └─Sequential (encoding_block): 2-4            [2, 256, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    └─ReflectionPad2d (0): 3-25              [2, 256, 32, 32]          [2, 256, 34, 34]          --\n",
       "│    │    └─Conv2d (1): 3-26                       [2, 256, 34, 34]          [2, 512, 32, 32]          1,180,160\n",
       "│    │    └─PReLU (2): 3-27                        [2, 512, 32, 32]          [2, 512, 32, 32]          1\n",
       "│    │    └─BatchNorm2d (3): 3-28                  [2, 512, 32, 32]          [2, 512, 32, 32]          1,024\n",
       "│    │    └─ReflectionPad2d (4): 3-29              [2, 512, 32, 32]          [2, 512, 34, 34]          --\n",
       "│    │    └─Conv2d (5): 3-30                       [2, 512, 34, 34]          [2, 512, 32, 32]          2,359,808\n",
       "│    │    └─PReLU (6): 3-31                        [2, 512, 32, 32]          [2, 512, 32, 32]          1\n",
       "│    │    └─BatchNorm2d (7): 3-32                  [2, 512, 32, 32]          [2, 512, 32, 32]          1,024\n",
       "├─MaxPool2d (maxpool4): 1-8                        [2, 512, 32, 32]          [2, 512, 16, 16]          --\n",
       "├─encoding_block (center): 1-9                     [2, 512, 16, 16]          [2, 1024, 16, 16]         --\n",
       "│    └─Sequential (encoding_block): 2-5            [2, 512, 16, 16]          [2, 1024, 16, 16]         --\n",
       "│    │    └─ReflectionPad2d (0): 3-33              [2, 512, 16, 16]          [2, 512, 18, 18]          --\n",
       "│    │    └─Conv2d (1): 3-34                       [2, 512, 18, 18]          [2, 1024, 16, 16]         4,719,616\n",
       "│    │    └─PReLU (2): 3-35                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         1\n",
       "│    │    └─BatchNorm2d (3): 3-36                  [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    └─ReflectionPad2d (4): 3-37              [2, 1024, 16, 16]         [2, 1024, 18, 18]         --\n",
       "│    │    └─Conv2d (5): 3-38                       [2, 1024, 18, 18]         [2, 1024, 16, 16]         9,438,208\n",
       "│    │    └─PReLU (6): 3-39                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         1\n",
       "│    │    └─BatchNorm2d (7): 3-40                  [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "├─decoding_block (decode4): 1-10                   [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    └─Sequential (up): 2-6                        [2, 1024, 16, 16]         [2, 512, 32, 32]          --\n",
       "│    │    └─Upsample (0): 3-41                     [2, 1024, 16, 16]         [2, 1024, 32, 32]         --\n",
       "│    │    └─Conv2d (1): 3-42                       [2, 1024, 32, 32]         [2, 512, 32, 32]          524,800\n",
       "│    └─encoding_block (conv): 2-7                  [2, 1024, 32, 32]         [2, 512, 32, 32]          --\n",
       "│    │    └─Sequential (encoding_block): 3-43      [2, 1024, 32, 32]         [2, 512, 32, 32]          --\n",
       "│    │    │    └─ReflectionPad2d (0): 4-1          [2, 1024, 32, 32]         [2, 1024, 34, 34]         --\n",
       "│    │    │    └─Conv2d (1): 4-2                   [2, 1024, 34, 34]         [2, 512, 32, 32]          4,719,104\n",
       "│    │    │    └─PReLU (2): 4-3                    [2, 512, 32, 32]          [2, 512, 32, 32]          1\n",
       "│    │    │    └─ReflectionPad2d (3): 4-4          [2, 512, 32, 32]          [2, 512, 34, 34]          --\n",
       "│    │    │    └─Conv2d (4): 4-5                   [2, 512, 34, 34]          [2, 512, 32, 32]          2,359,808\n",
       "│    │    │    └─PReLU (5): 4-6                    [2, 512, 32, 32]          [2, 512, 32, 32]          1\n",
       "├─decoding_block (decode3): 1-11                   [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    └─Sequential (up): 2-8                        [2, 512, 32, 32]          [2, 256, 64, 64]          --\n",
       "│    │    └─Upsample (0): 3-44                     [2, 512, 32, 32]          [2, 512, 64, 64]          --\n",
       "│    │    └─Conv2d (1): 3-45                       [2, 512, 64, 64]          [2, 256, 64, 64]          131,328\n",
       "│    └─encoding_block (conv): 2-9                  [2, 512, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─Sequential (encoding_block): 3-46      [2, 512, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    └─ReflectionPad2d (0): 4-7          [2, 512, 64, 64]          [2, 512, 66, 66]          --\n",
       "│    │    │    └─Conv2d (1): 4-8                   [2, 512, 66, 66]          [2, 256, 64, 64]          1,179,904\n",
       "│    │    │    └─PReLU (2): 4-9                    [2, 256, 64, 64]          [2, 256, 64, 64]          1\n",
       "│    │    │    └─ReflectionPad2d (3): 4-10         [2, 256, 64, 64]          [2, 256, 66, 66]          --\n",
       "│    │    │    └─Conv2d (4): 4-11                  [2, 256, 66, 66]          [2, 256, 64, 64]          590,080\n",
       "│    │    │    └─PReLU (5): 4-12                   [2, 256, 64, 64]          [2, 256, 64, 64]          1\n",
       "├─decoding_block (decode2): 1-12                   [2, 128, 128, 128]        [2, 128, 128, 128]        --\n",
       "│    └─Sequential (up): 2-10                       [2, 256, 64, 64]          [2, 128, 128, 128]        --\n",
       "│    │    └─Upsample (0): 3-47                     [2, 256, 64, 64]          [2, 256, 128, 128]        --\n",
       "│    │    └─Conv2d (1): 3-48                       [2, 256, 128, 128]        [2, 128, 128, 128]        32,896\n",
       "│    └─encoding_block (conv): 2-11                 [2, 256, 128, 128]        [2, 128, 128, 128]        --\n",
       "│    │    └─Sequential (encoding_block): 3-49      [2, 256, 128, 128]        [2, 128, 128, 128]        --\n",
       "│    │    │    └─ReflectionPad2d (0): 4-13         [2, 256, 128, 128]        [2, 256, 130, 130]        --\n",
       "│    │    │    └─Conv2d (1): 4-14                  [2, 256, 130, 130]        [2, 128, 128, 128]        295,040\n",
       "│    │    │    └─PReLU (2): 4-15                   [2, 128, 128, 128]        [2, 128, 128, 128]        1\n",
       "│    │    │    └─ReflectionPad2d (3): 4-16         [2, 128, 128, 128]        [2, 128, 130, 130]        --\n",
       "│    │    │    └─Conv2d (4): 4-17                  [2, 128, 130, 130]        [2, 128, 128, 128]        147,584\n",
       "│    │    │    └─PReLU (5): 4-18                   [2, 128, 128, 128]        [2, 128, 128, 128]        1\n",
       "├─decoding_block (decode1): 1-13                   [2, 64, 256, 256]         [2, 64, 256, 256]         --\n",
       "│    └─Sequential (up): 2-12                       [2, 128, 128, 128]        [2, 64, 256, 256]         --\n",
       "│    │    └─Upsample (0): 3-50                     [2, 128, 128, 128]        [2, 128, 256, 256]        --\n",
       "│    │    └─Conv2d (1): 3-51                       [2, 128, 256, 256]        [2, 64, 256, 256]         8,256\n",
       "│    └─encoding_block (conv): 2-13                 [2, 128, 256, 256]        [2, 64, 256, 256]         --\n",
       "│    │    └─Sequential (encoding_block): 3-52      [2, 128, 256, 256]        [2, 64, 256, 256]         --\n",
       "│    │    │    └─ReflectionPad2d (0): 4-19         [2, 128, 256, 256]        [2, 128, 258, 258]        --\n",
       "│    │    │    └─Conv2d (1): 4-20                  [2, 128, 258, 258]        [2, 64, 256, 256]         73,792\n",
       "│    │    │    └─PReLU (2): 4-21                   [2, 64, 256, 256]         [2, 64, 256, 256]         1\n",
       "│    │    │    └─ReflectionPad2d (3): 4-22         [2, 64, 256, 256]         [2, 64, 258, 258]         --\n",
       "│    │    │    └─Conv2d (4): 4-23                  [2, 64, 258, 258]         [2, 64, 256, 256]         36,928\n",
       "│    │    │    └─PReLU (5): 4-24                   [2, 64, 256, 256]         [2, 64, 256, 256]         1\n",
       "├─Conv2d (final_cls): 1-14                         [2, 64, 256, 256]         [2, 7, 256, 256]          455\n",
       "├─Conv2d (final_reg): 1-15                         [2, 64, 256, 256]         [2, 1, 256, 256]          65\n",
       "=============================================================================================================================\n",
       "Total params: 28,951,770\n",
       "Trainable params: 28,951,770\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 96.55\n",
       "=============================================================================================================================\n",
       "Input size (MB): 2.10\n",
       "Forward/backward pass size (MB): 1417.67\n",
       "Params size (MB): 115.81\n",
       "Estimated Total Size (MB): 1535.58\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from models.unet import UNet_carbon\n",
    "\n",
    "model = UNet_carbon(num_classes=7)\n",
    "summary(model,col_names=(\"input_size\",\"output_size\",\"num_params\",),row_settings=('var_names','depth'), depth=10,input_size=(2, 4, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwoo/anaconda3/envs/transformer/lib/python3.12/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name vit_base_resnet50_384 to current vit_base_r50_s16_384.orig_in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                                                Input Shape               Output Shape              Param #\n",
       "===========================================================================================================================================================\n",
       "DPTSegmentationModel (DPTSegmentationModel)                                      [2, 4, 256, 256]          [2, 4, 256, 256]          591,364\n",
       "├─Module (pretrained): 1-1                                                       --                        --                        --\n",
       "│    └─VisionTransformer (model): 2-1                                            --                        --                        1,212,904\n",
       "│    │    └─HybridEmbed (patch_embed): 3-1                                       --                        --                        --\n",
       "│    │    │    └─ResNetV2 (backbone): 4-1                                        [2, 4, 256, 256]          [2, 1024, 16, 16]         --\n",
       "│    │    │    │    └─Sequential (stem): 5-1                                     [2, 4, 256, 256]          [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    └─StdConv2dSame (conv): 6-1                             [2, 4, 256, 256]          [2, 64, 128, 128]         12,544\n",
       "│    │    │    │    │    └─GroupNormAct (norm): 6-2                              [2, 64, 128, 128]         [2, 64, 128, 128]         128\n",
       "│    │    │    │    │    │    └─Identity (drop): 7-1                             [2, 64, 128, 128]         [2, 64, 128, 128]         --\n",
       "│    │    │    │    │    │    └─ReLU (act): 7-2                                  [2, 64, 128, 128]         [2, 64, 128, 128]         --\n",
       "│    │    │    │    │    └─MaxPool2dSame (pool): 6-3                             [2, 64, 128, 128]         [2, 64, 64, 64]           --\n",
       "│    │    │    │    └─Sequential (stages): 5-2                                   [2, 64, 64, 64]           [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─ResNetStage (0): 6-4                                  [2, 64, 64, 64]           [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    └─Sequential (blocks): 7-3                         [2, 64, 64, 64]           [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (0): 8-1                         [2, 64, 64, 64]           [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─DownsampleConv (downsample): 9-1       [2, 64, 64, 64]           [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    │    └─StdConv2dSame (conv): 10-1        [2, 64, 64, 64]           [2, 256, 64, 64]          16,384\n",
       "│    │    │    │    │    │    │    │    │    └─GroupNormAct (norm): 10-2         [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-2             [2, 64, 64, 64]           [2, 64, 64, 64]           4,096\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-3              [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-3             [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-4                  [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-4             [2, 64, 64, 64]           [2, 64, 64, 64]           36,864\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-5              [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-5             [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-6                  [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-6             [2, 64, 64, 64]           [2, 256, 64, 64]          16,384\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-7              [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-7             [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-8              [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-8              [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-9                       [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (1): 8-2                         [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-10            [2, 256, 64, 64]          [2, 64, 64, 64]           16,384\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-11             [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-9             [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-10                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-12            [2, 64, 64, 64]           [2, 64, 64, 64]           36,864\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-13             [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-11            [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-12                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-14            [2, 64, 64, 64]           [2, 256, 64, 64]          16,384\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-15             [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-13            [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-14             [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-16             [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-17                      [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (2): 8-3                         [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-18            [2, 256, 64, 64]          [2, 64, 64, 64]           16,384\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-19             [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-15            [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-16                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-20            [2, 64, 64, 64]           [2, 64, 64, 64]           36,864\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-21             [2, 64, 64, 64]           [2, 64, 64, 64]           128\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-17            [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-18                 [2, 64, 64, 64]           [2, 64, 64, 64]           --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-22            [2, 64, 64, 64]           [2, 256, 64, 64]          16,384\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-23             [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-19            [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-20             [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-24             [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-25                      [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    │    │    └─ResNetStage (1): 6-5                                  [2, 256, 64, 64]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    └─Sequential (blocks): 7-4                         [2, 256, 64, 64]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (0): 8-4                         [2, 256, 64, 64]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─DownsampleConv (downsample): 9-26      [2, 256, 64, 64]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─StdConv2dSame (conv): 10-21       [2, 256, 64, 64]          [2, 512, 32, 32]          131,072\n",
       "│    │    │    │    │    │    │    │    │    └─GroupNormAct (norm): 10-22        [2, 512, 32, 32]          [2, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-27            [2, 256, 64, 64]          [2, 128, 64, 64]          32,768\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-28             [2, 128, 64, 64]          [2, 128, 64, 64]          256\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-23            [2, 128, 64, 64]          [2, 128, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-24                 [2, 128, 64, 64]          [2, 128, 64, 64]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-29            [2, 128, 64, 64]          [2, 128, 32, 32]          147,456\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-30             [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-25            [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-26                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-31            [2, 128, 32, 32]          [2, 512, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-32             [2, 512, 32, 32]          [2, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-27            [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-28             [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-33             [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-34                      [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (1): 8-5                         [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-35            [2, 512, 32, 32]          [2, 128, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-36             [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-29            [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-30                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-37            [2, 128, 32, 32]          [2, 128, 32, 32]          147,456\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-38             [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-31            [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-32                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-39            [2, 128, 32, 32]          [2, 512, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-40             [2, 512, 32, 32]          [2, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-33            [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-34             [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-41             [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-42                      [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (2): 8-6                         [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-43            [2, 512, 32, 32]          [2, 128, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-44             [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-35            [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-36                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-45            [2, 128, 32, 32]          [2, 128, 32, 32]          147,456\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-46             [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-37            [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-38                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-47            [2, 128, 32, 32]          [2, 512, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-48             [2, 512, 32, 32]          [2, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-39            [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-40             [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-49             [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-50                      [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (3): 8-7                         [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-51            [2, 512, 32, 32]          [2, 128, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-52             [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-41            [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-42                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-53            [2, 128, 32, 32]          [2, 128, 32, 32]          147,456\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-54             [2, 128, 32, 32]          [2, 128, 32, 32]          256\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-43            [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-44                 [2, 128, 32, 32]          [2, 128, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-55            [2, 128, 32, 32]          [2, 512, 32, 32]          65,536\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-56             [2, 512, 32, 32]          [2, 512, 32, 32]          1,024\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-45            [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-46             [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-57             [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-58                      [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    │    │    │    └─ResNetStage (2): 6-6                                  [2, 512, 32, 32]          [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─Sequential (blocks): 7-5                         [2, 512, 32, 32]          [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (0): 8-8                         [2, 512, 32, 32]          [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─DownsampleConv (downsample): 9-59      [2, 512, 32, 32]          [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─StdConv2dSame (conv): 10-47       [2, 512, 32, 32]          [2, 1024, 16, 16]         524,288\n",
       "│    │    │    │    │    │    │    │    │    └─GroupNormAct (norm): 10-48        [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-60            [2, 512, 32, 32]          [2, 256, 32, 32]          131,072\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-61             [2, 256, 32, 32]          [2, 256, 32, 32]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-49            [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-50                 [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-62            [2, 256, 32, 32]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-63             [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-51            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-52                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-64            [2, 256, 16, 16]          [2, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-65             [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-53            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-54             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-66             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-67                      [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (1): 8-9                         [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-68            [2, 1024, 16, 16]         [2, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-69             [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-55            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-56                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-70            [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-71             [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-57            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-58                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-72            [2, 256, 16, 16]          [2, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-73             [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-59            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-60             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-74             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-75                      [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (2): 8-10                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-76            [2, 1024, 16, 16]         [2, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-77             [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-61            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-62                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-78            [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-79             [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-63            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-64                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-80            [2, 256, 16, 16]          [2, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-81             [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-65            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-66             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-82             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-83                      [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (3): 8-11                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-84            [2, 1024, 16, 16]         [2, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-85             [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-67            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-68                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-86            [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-87             [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-69            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-70                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-88            [2, 256, 16, 16]          [2, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-89             [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-71            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-72             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-90             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-91                      [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (4): 8-12                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-92            [2, 1024, 16, 16]         [2, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-93             [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-73            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-74                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-94            [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-95             [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-75            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-76                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-96            [2, 256, 16, 16]          [2, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-97             [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-77            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-78             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-98             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-99                      [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (5): 8-13                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-100           [2, 1024, 16, 16]         [2, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-101            [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-79            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-80                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-102           [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-103            [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-81            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-82                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-104           [2, 256, 16, 16]          [2, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-105            [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-83            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-84             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-106            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-107                     [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (6): 8-14                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-108           [2, 1024, 16, 16]         [2, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-109            [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-85            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-86                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-110           [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-111            [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-87            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-88                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-112           [2, 256, 16, 16]          [2, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-113            [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-89            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-90             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-114            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-115                     [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (7): 8-15                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-116           [2, 1024, 16, 16]         [2, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-117            [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-91            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-92                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-118           [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-119            [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-93            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-94                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-120           [2, 256, 16, 16]          [2, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-121            [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-95            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-96             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-122            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-123                     [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    └─Bottleneck (8): 8-16                        [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv1): 9-124           [2, 1024, 16, 16]         [2, 256, 16, 16]          262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm1): 9-125            [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-97            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-98                 [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv2): 9-126           [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm2): 9-127            [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-99            [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    │    └─ReLU (act): 10-100                [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    │    │    │    │    │    └─StdConv2dSame (conv3): 9-128           [2, 256, 16, 16]          [2, 1024, 16, 16]         262,144\n",
       "│    │    │    │    │    │    │    │    └─GroupNormAct (norm3): 9-129            [2, 1024, 16, 16]         [2, 1024, 16, 16]         2,048\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (drop): 10-101           [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    │    └─Identity (act): 10-102            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─Identity (drop_path): 9-130            [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    │    │    └─ReLU (act3): 9-131                     [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    └─Identity (norm): 5-3                                       [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    └─ClassifierHead (head): 5-4                                 [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─SelectAdaptivePool2d (global_pool): 6-7               [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─Identity (pool): 7-6                             [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    │    └─Identity (flatten): 7-7                          [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Dropout (drop): 6-8                                   [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Identity (fc): 6-9                                    [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    │    │    └─Identity (flatten): 6-10                              [2, 1024, 16, 16]         [2, 1024, 16, 16]         --\n",
       "│    │    │    └─Conv2d (proj): 4-2                                              [2, 1024, 16, 16]         [2, 768, 16, 16]          787,200\n",
       "│    │    └─Dropout (pos_drop): 3-2                                              [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    └─Sequential (blocks): 3-3                                             --                        --                        --\n",
       "│    │    │    └─Block (0): 4-3                                                  [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-5                                     [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-6                                      [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-11                                    [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-12                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-13                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-14                                   [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-15                             [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-7                                        [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-8                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-9                                     [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-10                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-16                                    [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-17                                      [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-18                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-19                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-20                                    [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-21                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-11                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-12                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (1): 4-4                                                  [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-13                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-14                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-22                                    [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-23                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-24                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-25                                   [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-26                             [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-15                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-16                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-17                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-18                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-27                                    [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-28                                      [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-29                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-30                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-31                                    [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-32                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-19                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-20                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (2): 4-5                                                  [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-21                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-22                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-33                                    [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-34                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-35                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-36                                   [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-37                             [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-23                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-24                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-25                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-26                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-38                                    [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-39                                      [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-40                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-41                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-42                                    [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-43                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-27                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-28                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (3): 4-6                                                  [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-29                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-30                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-44                                    [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-45                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-46                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-47                                   [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-48                             [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-31                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-32                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-33                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-34                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-49                                    [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-50                                      [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-51                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-52                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-53                                    [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-54                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-35                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-36                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (4): 4-7                                                  [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-37                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-38                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-55                                    [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-56                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-57                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-58                                   [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-59                             [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-39                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-40                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-41                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-42                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-60                                    [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-61                                      [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-62                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-63                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-64                                    [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-65                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-43                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-44                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (5): 4-8                                                  [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-45                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-46                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-66                                    [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-67                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-68                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-69                                   [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-70                             [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-47                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-48                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-49                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-50                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-71                                    [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-72                                      [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-73                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-74                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-75                                    [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-76                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-51                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-52                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (6): 4-9                                                  [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-53                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-54                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-77                                    [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-78                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-79                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-80                                   [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-81                             [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-55                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-56                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-57                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-58                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-82                                    [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-83                                      [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-84                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-85                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-86                                    [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-87                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-59                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-60                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (7): 4-10                                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-61                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-62                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-88                                    [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-89                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-90                               [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-91                                   [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-92                             [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-63                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-64                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-65                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-66                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-93                                    [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-94                                      [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-95                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-96                                 [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-97                                    [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-98                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-67                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-68                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (8): 4-11                                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-69                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-70                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-99                                    [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-100                              [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-101                              [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-102                                  [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-103                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-71                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-72                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-73                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-74                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-104                                   [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-105                                     [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-106                                [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-107                                [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-108                                   [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-109                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-75                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-76                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (9): 4-12                                                 [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-77                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-78                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-110                                   [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-111                              [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-112                              [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-113                                  [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-114                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-79                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-80                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-81                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-82                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-115                                   [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-116                                     [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-117                                [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-118                                [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-119                                   [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-120                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-83                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-84                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (10): 4-13                                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-85                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-86                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-121                                   [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-122                              [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-123                              [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-124                                  [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-125                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-87                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-88                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-89                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-90                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-126                                   [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-127                                     [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-128                                [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-129                                [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-130                                   [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-131                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-91                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-92                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    └─Block (11): 4-14                                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm1): 5-93                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Attention (attn): 5-94                                     [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (qkv): 6-132                                   [2, 257, 768]             [2, 257, 2304]            1,771,776\n",
       "│    │    │    │    │    └─Identity (q_norm): 6-133                              [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Identity (k_norm): 6-134                              [2, 12, 257, 64]          [2, 12, 257, 64]          --\n",
       "│    │    │    │    │    └─Linear (proj): 6-135                                  [2, 257, 768]             [2, 257, 768]             590,592\n",
       "│    │    │    │    │    └─Dropout (proj_drop): 6-136                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls1): 5-95                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path1): 5-96                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─LayerNorm (norm2): 5-97                                    [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    │    │    │    └─Mlp (mlp): 5-98                                            [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    │    └─Linear (fc1): 6-137                                   [2, 257, 768]             [2, 257, 3072]            2,362,368\n",
       "│    │    │    │    │    └─GELU (act): 6-138                                     [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Dropout (drop1): 6-139                                [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Identity (norm): 6-140                                [2, 257, 3072]            [2, 257, 3072]            --\n",
       "│    │    │    │    │    └─Linear (fc2): 6-141                                   [2, 257, 3072]            [2, 257, 768]             2,360,064\n",
       "│    │    │    │    │    └─Dropout (drop2): 6-142                                [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (ls2): 5-99                                       [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    │    │    └─Identity (drop_path2): 5-100                               [2, 257, 768]             [2, 257, 768]             --\n",
       "│    │    └─LayerNorm (norm): 3-4                                                [2, 257, 768]             [2, 257, 768]             1,536\n",
       "│    └─Sequential (act_postprocess1): 2-2                                        --                        --                        --\n",
       "│    │    └─Identity (0): 3-5                                                    [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─Identity (1): 3-6                                                    [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    └─Sequential (act_postprocess2): 2-3                                        --                        --                        --\n",
       "│    │    └─Identity (0): 3-7                                                    [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    │    └─Identity (1): 3-8                                                    [2, 512, 32, 32]          [2, 512, 32, 32]          --\n",
       "│    └─Sequential (act_postprocess3): 2-6                                        --                        --                        (recursive)\n",
       "│    │    └─ProjectReadout (0): 3-9                                              [2, 257, 768]             [2, 256, 768]             --\n",
       "│    │    │    └─Sequential (project): 4-15                                      [2, 256, 1536]            [2, 256, 768]             --\n",
       "│    │    │    │    └─Linear (0): 5-101                                          [2, 256, 1536]            [2, 256, 768]             1,180,416\n",
       "│    │    │    │    └─GELU (1): 5-102                                            [2, 256, 768]             [2, 256, 768]             --\n",
       "│    │    └─Transpose (1): 3-10                                                  [2, 256, 768]             [2, 768, 256]             --\n",
       "│    └─Sequential (act_postprocess4): 2-7                                        --                        --                        (recursive)\n",
       "│    │    └─ProjectReadout (0): 3-11                                             [2, 257, 768]             [2, 256, 768]             --\n",
       "│    │    │    └─Sequential (project): 4-16                                      [2, 256, 1536]            [2, 256, 768]             --\n",
       "│    │    │    │    └─Linear (0): 5-103                                          [2, 256, 1536]            [2, 256, 768]             1,180,416\n",
       "│    │    │    │    └─GELU (1): 5-104                                            [2, 256, 768]             [2, 256, 768]             --\n",
       "│    │    └─Transpose (1): 3-12                                                  [2, 256, 768]             [2, 768, 256]             --\n",
       "│    └─Sequential (act_postprocess3): 2-6                                        --                        --                        (recursive)\n",
       "│    │    └─Conv2d (3): 3-13                                                     [2, 768, 16, 16]          [2, 768, 16, 16]          590,592\n",
       "│    └─Sequential (act_postprocess4): 2-7                                        --                        --                        (recursive)\n",
       "│    │    └─Conv2d (3): 3-14                                                     [2, 768, 16, 16]          [2, 768, 16, 16]          590,592\n",
       "│    │    └─Conv2d (4): 3-15                                                     [2, 768, 16, 16]          [2, 768, 8, 8]            5,309,184\n",
       "├─Module (scratch): 1-2                                                          --                        --                        --\n",
       "│    └─Conv2d (layer1_rn): 2-8                                                   [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    └─Conv2d (layer2_rn): 2-9                                                   [2, 512, 32, 32]          [2, 256, 32, 32]          1,179,648\n",
       "│    └─Conv2d (layer3_rn): 2-10                                                  [2, 768, 16, 16]          [2, 256, 16, 16]          1,769,472\n",
       "│    └─Conv2d (layer4_rn): 2-11                                                  [2, 768, 8, 8]            [2, 256, 8, 8]            1,769,472\n",
       "│    └─FeatureFusionBlock_custom (refinenet4): 2-12                              [2, 256, 8, 8]            [2, 256, 16, 16]          1,180,672\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-16                         [2, 256, 8, 8]            [2, 256, 8, 8]            --\n",
       "│    │    │    └─ReLU (activation): 4-17                                         [2, 256, 8, 8]            [2, 256, 8, 8]            --\n",
       "│    │    │    └─Conv2d (conv1): 4-18                                            [2, 256, 8, 8]            [2, 256, 8, 8]            589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-19                                         [2, 256, 8, 8]            [2, 256, 8, 8]            512\n",
       "│    │    │    └─ReLU (activation): 4-20                                         [2, 256, 8, 8]            [2, 256, 8, 8]            --\n",
       "│    │    │    └─Conv2d (conv2): 4-21                                            [2, 256, 8, 8]            [2, 256, 8, 8]            589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-22                                         [2, 256, 8, 8]            [2, 256, 8, 8]            512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-23                                --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-105                  [2, 256, 8, 8]            [2, 256, 8, 8]            --\n",
       "│    │    └─Conv2d (out_conv): 3-17                                              [2, 256, 16, 16]          [2, 256, 16, 16]          65,792\n",
       "│    └─FeatureFusionBlock_custom (refinenet3): 2-13                              [2, 256, 16, 16]          [2, 256, 32, 32]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-18                         [2, 256, 16, 16]          [2, 256, 16, 16]          1,180,672\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-21                         --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-24                                         [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-22                         --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv1): 4-25                                            [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-26                                         [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-21                         --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-27                                         [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-22                         --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv2): 4-28                                            [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-29                                         [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-30                                --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-106                  [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─FloatFunctional (skip_add): 3-23                                     --                        --                        --\n",
       "│    │    │    └─Identity (activation_post_process): 4-31                        [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-24                         [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    └─ReLU (activation): 4-32                                         [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d (conv1): 4-33                                            [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-34                                         [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    └─ReLU (activation): 4-35                                         [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    │    └─Conv2d (conv2): 4-36                                            [2, 256, 16, 16]          [2, 256, 16, 16]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-37                                         [2, 256, 16, 16]          [2, 256, 16, 16]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-38                                --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-107                  [2, 256, 16, 16]          [2, 256, 16, 16]          --\n",
       "│    │    └─Conv2d (out_conv): 3-25                                              [2, 256, 32, 32]          [2, 256, 32, 32]          65,792\n",
       "│    └─FeatureFusionBlock_custom (refinenet2): 2-14                              [2, 256, 32, 32]          [2, 256, 64, 64]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-26                         [2, 256, 32, 32]          [2, 256, 32, 32]          1,180,672\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-29                         --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-39                                         [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-30                         --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv1): 4-40                                            [2, 256, 32, 32]          [2, 256, 32, 32]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-41                                         [2, 256, 32, 32]          [2, 256, 32, 32]          512\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-29                         --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-42                                         [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-30                         --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv2): 4-43                                            [2, 256, 32, 32]          [2, 256, 32, 32]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-44                                         [2, 256, 32, 32]          [2, 256, 32, 32]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-45                                --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-108                  [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─FloatFunctional (skip_add): 3-31                                     --                        --                        --\n",
       "│    │    │    └─Identity (activation_post_process): 4-46                        [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-32                         [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    │    └─ReLU (activation): 4-47                                         [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    │    └─Conv2d (conv1): 4-48                                            [2, 256, 32, 32]          [2, 256, 32, 32]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-49                                         [2, 256, 32, 32]          [2, 256, 32, 32]          512\n",
       "│    │    │    └─ReLU (activation): 4-50                                         [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    │    └─Conv2d (conv2): 4-51                                            [2, 256, 32, 32]          [2, 256, 32, 32]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-52                                         [2, 256, 32, 32]          [2, 256, 32, 32]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-53                                --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-109                  [2, 256, 32, 32]          [2, 256, 32, 32]          --\n",
       "│    │    └─Conv2d (out_conv): 3-33                                              [2, 256, 64, 64]          [2, 256, 64, 64]          65,792\n",
       "│    └─FeatureFusionBlock_custom (refinenet1): 2-15                              [2, 256, 64, 64]          [2, 256, 128, 128]        --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-34                         [2, 256, 64, 64]          [2, 256, 64, 64]          1,180,672\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-37                         --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-54                                         [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-38                         --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv1): 4-55                                            [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-56                                         [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-37                         --                        --                        (recursive)\n",
       "│    │    │    └─ReLU (activation): 4-57                                         [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit1): 3-38                         --                        --                        (recursive)\n",
       "│    │    │    └─Conv2d (conv2): 4-58                                            [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-59                                         [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-60                                --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-110                  [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─FloatFunctional (skip_add): 3-39                                     --                        --                        --\n",
       "│    │    │    └─Identity (activation_post_process): 4-61                        [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─ResidualConvUnit_custom (resConfUnit2): 3-40                         [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    └─ReLU (activation): 4-62                                         [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    └─Conv2d (conv1): 4-63                                            [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn1): 4-64                                         [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    └─ReLU (activation): 4-65                                         [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    │    └─Conv2d (conv2): 4-66                                            [2, 256, 64, 64]          [2, 256, 64, 64]          589,824\n",
       "│    │    │    └─BatchNorm2d (bn2): 4-67                                         [2, 256, 64, 64]          [2, 256, 64, 64]          512\n",
       "│    │    │    └─FloatFunctional (skip_add): 4-68                                --                        --                        --\n",
       "│    │    │    │    └─Identity (activation_post_process): 5-111                  [2, 256, 64, 64]          [2, 256, 64, 64]          --\n",
       "│    │    └─Conv2d (out_conv): 3-41                                              [2, 256, 128, 128]        [2, 256, 128, 128]        65,792\n",
       "│    └─Sequential (output_conv): 2-16                                            [2, 256, 128, 128]        [2, 4, 256, 256]          --\n",
       "│    │    └─Conv2d (0): 3-42                                                     [2, 256, 128, 128]        [2, 256, 128, 128]        589,824\n",
       "│    │    └─BatchNorm2d (1): 3-43                                                [2, 256, 128, 128]        [2, 256, 128, 128]        512\n",
       "│    │    └─ReLU (2): 3-44                                                       [2, 256, 128, 128]        [2, 256, 128, 128]        --\n",
       "│    │    └─Dropout (3): 3-45                                                    [2, 256, 128, 128]        [2, 256, 128, 128]        --\n",
       "│    │    └─Conv2d (4): 3-46                                                     [2, 256, 128, 128]        [2, 4, 128, 128]          1,028\n",
       "│    │    └─Interpolate (5): 3-47                                                [2, 4, 128, 128]          [2, 4, 256, 256]          --\n",
       "===========================================================================================================================================================\n",
       "Total params: 127,546,992\n",
       "Trainable params: 127,546,992\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 68.36\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 2.10\n",
       "Forward/backward pass size (MB): 1098.44\n",
       "Params size (MB): 483.92\n",
       "Estimated Total Size (MB): 1584.46\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.dpt import DPTSegmentationModel\n",
    "\n",
    "model = DPTSegmentationModel(backbone = \"vitl16_384\",num_classes=4)\n",
    "summary(model,col_names=(\"input_size\",\"output_size\",\"num_params\",),row_settings=('var_names','depth'), depth=10,input_size=(2, 4, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
